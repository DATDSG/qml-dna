{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c28adf8a",
   "metadata": {},
   "source": [
    "# 05_noise_robustness.ipynb ‚Äî sweep shots & noise for QSVM + VQC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e11b11",
   "metadata": {},
   "source": [
    "# Cell 0 ‚Äî perf env (keep structure; nicer output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaea2964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure deterministic thread counts and lightweight timing utilities for the sweep\n",
    "import os\n",
    "os.environ.setdefault(\"OMP_NUM_THREADS\", \"8\")\n",
    "os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"8\")\n",
    "os.environ.setdefault(\"MKL_NUM_THREADS\", \"8\")\n",
    "os.environ.setdefault(\"NUMEXPR_NUM_THREADS\", \"8\")\n",
    "print(\"BLAS threads:\",\n",
    "      os.environ.get(\"OMP_NUM_THREADS\"),\n",
    "      os.environ.get(\"OPENBLAS_NUM_THREADS\"),\n",
    "      os.environ.get(\"MKL_NUM_THREADS\"),\n",
    "      os.environ.get(\"NUMEXPR_NUM_THREADS\"))\n",
    "\n",
    "import time, json\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict\n",
    "\n",
    "class PhaseTimer:\n",
    "    def __init__(self): self.t = defaultdict(float)\n",
    "    @contextmanager\n",
    "    def timed(self, key):\n",
    "        t0 = time.perf_counter()\n",
    "        yield\n",
    "        self.t[key] += time.perf_counter() - t0\n",
    "    def add(self, key, seconds): self.t[key] += seconds\n",
    "    def to_dict(self): return dict(self.t)\n",
    "\n",
    "def pretty_seconds(sec):\n",
    "    return f\"{sec/60:.1f} min\" if sec >= 60 else f\"{sec:.1f} s\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35090e4",
   "metadata": {},
   "source": [
    "# Cell 1 ‚Äî imports, dirs, RunJournal (step logs saved to Markdown + JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3220d122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports and directory setup; include robust template import for older/newer PennyLane versions\n",
    "from pathlib import Path\n",
    "import itertools, warnings, numpy as np, pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix,\n",
    "    balanced_accuracy_score, matthews_corrcoef, classification_report, average_precision_score\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# PennyLane template import (version-robust)\n",
    "try:\n",
    "    BasicEntanglerLayers = qml.BasicEntanglerLayers\n",
    "except AttributeError:\n",
    "    from pennylane.templates.layers import BasicEntanglerLayers\n",
    "\n",
    "ROOT = Path(\".\")\n",
    "PROCESSED = ROOT/\"data/processed\"\n",
    "RESULTS = ROOT/\"results\"\n",
    "(RESULTS / \"metrics\").mkdir(parents=True, exist_ok=True)\n",
    "(RESULTS / \"kernels\").mkdir(parents=True, exist_ok=True)\n",
    "(RESULTS / \"cache\").mkdir(parents=True, exist_ok=True)\n",
    "(RESULTS / \"plots\").mkdir(parents=True, exist_ok=True)\n",
    "(RESULTS / \"logs\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.random.seed(17); pnp.random.seed(17)\n",
    "\n",
    "# --- Run Journal: print + save Markdown/JSON for documentation ---\n",
    "class RunJournal:\n",
    "    def __init__(self): self.events = []\n",
    "    def log(self, step, status, message, **extras):\n",
    "        row = {\"ts\": time.strftime(\"%Y-%m-%d %H:%M:%S\"), \"step\": step, \"status\": status, \"message\": message}\n",
    "        row.update(extras)\n",
    "        self.events.append(row)\n",
    "        sym = \"‚úÖ\" if status == \"ok\" else (\"‚ö†Ô∏è\" if status == \"warn\" else \"‚ùå\")\n",
    "        print(f\"{sym} [{step}] {message}\")\n",
    "    def df(self): return pd.DataFrame(self.events)\n",
    "    def save(self, basepath: Path):\n",
    "        df = self.df()\n",
    "        md = [\"| ts | step | status | message |\", \"|---|---|---|---|\"]\n",
    "        for _, r in df.iterrows():\n",
    "            md.append(f\"| {r.ts} | {r.step} | {r.status} | {r.message} |\")\n",
    "        (basepath.with_suffix(\".md\")).write_text(\"\\n\".join(md), encoding=\"utf-8\")\n",
    "        (basepath.with_suffix(\".json\")).write_text(df.to_json(orient=\"records\", indent=2), encoding=\"utf-8\")\n",
    "        print(f\"üìù Saved journal:\\n  - {basepath.with_suffix('.md')}\\n  - {basepath.with_suffix('.json')}\")\n",
    "\n",
    "J = RunJournal()\n",
    "J.log(\"init\", \"ok\", \"Noise robustness sweep notebook initialized; directories ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb6e8c8",
   "metadata": {},
   "source": [
    "# Cell 2 ‚Äî knobs (speed vs accuracy; clearly printed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a59bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define experiment size/quality presets controlling data subsampling, anchor count, shots, and noise grids\n",
    "PRESET = \"turbo\"  # Options: \"turbo\" (fastest), \"fast\", \"full\"\n",
    "\n",
    "if PRESET == \"turbo\":\n",
    "    D = 6; MAX_TR = 160; M_ANCHORS = 96\n",
    "    shots_grid  = [256]\n",
    "    pflip_grid  = [0.0, 0.01]\n",
    "    pdepol_grid = [0.0]\n",
    "elif PRESET == \"fast\":\n",
    "    D = 6; MAX_TR = 220; M_ANCHORS = 128\n",
    "    shots_grid  = [256, 512]\n",
    "    pflip_grid  = [0.0, 0.01]\n",
    "    pdepol_grid = [0.0, 0.01]\n",
    "else:  # full\n",
    "    D = 6; MAX_TR = 300; M_ANCHORS = 192\n",
    "    shots_grid  = [512, 2000]\n",
    "    pflip_grid  = [0.0, 0.01]\n",
    "    pdepol_grid = [0.0, 0.01]\n",
    "\n",
    "SWEEP = list(itertools.product(shots_grid, pflip_grid, pdepol_grid))\n",
    "print(f\"Preset={PRESET} | Sweep size: {len(SWEEP)} configs\")\n",
    "J.log(\"config\", \"ok\", f\"Preset={PRESET}, D={D}, MAX_TR={MAX_TR}, M_ANCHORS={M_ANCHORS}, sweep={len(SWEEP)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a2fe66",
   "metadata": {},
   "source": [
    "# Cell 3 ‚Äî load & PCA (multi-dataset aware; logs outcomes & problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b95d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature encodings; apply PCA + scaling; optionally truncate training set for speed\n",
    "enc_path = PROCESSED/\"encodings_all.npz\" if (PROCESSED/\"encodings_all.npz\").exists() else PROCESSED/\"encodings.npz\"\n",
    "spl_path = PROCESSED/\"splits_pooled.json\" if (PROCESSED/\"splits_pooled.json\").exists() else PROCESSED/\"splits.json\"\n",
    "\n",
    "data = np.load(enc_path, allow_pickle=True)\n",
    "import json\n",
    "with open(spl_path) as f: SPL = json.load(f)\n",
    "J.log(\"load\", \"ok\", f\"Loaded encodings from {enc_path.name} and splits from {spl_path.name}\")\n",
    "\n",
    "y = data[\"y\"].astype(int)\n",
    "X_kmer = data[\"kmer\"].astype(np.float32)\n",
    "tr_idx = np.array(SPL[\"train\"]); va_idx = np.array(SPL[\"val\"]); te_idx = np.array(SPL[\"test\"])\n",
    "\n",
    "pca = PCA(n_components=D, random_state=17)\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "\n",
    "X_tr_pca = pca.fit_transform(X_kmer[tr_idx])\n",
    "X_va_pca = pca.transform(X_kmer[va_idx])\n",
    "X_te_pca = pca.transform(X_kmer[te_idx])\n",
    "\n",
    "Xtr = scaler.fit_transform(X_tr_pca).astype(np.float32)\n",
    "Xva = scaler.transform(X_va_pca).astype(np.float32)\n",
    "Xte = scaler.transform(X_te_pca).astype(np.float32)\n",
    "\n",
    "ytr, yva, yte = y[tr_idx], y[va_idx], y[te_idx]\n",
    "sel = np.arange(min(MAX_TR, len(Xtr)))\n",
    "Xtr_s, ytr_s = Xtr[sel], ytr[sel]\n",
    "\n",
    "print(\"Shapes:\", Xtr.shape, Xva.shape, Xte.shape, \"| train subset:\", Xtr_s.shape)\n",
    "J.log(\"pca_scale\", \"ok\", f\"PCA D={D} (explained_var={pca.explained_variance_ratio_.sum():.3f}); subset_train={Xtr_s.shape}\")\n",
    "if len(np.unique(ytr_s)) < 2:\n",
    "    J.log(\"limitation\", \"warn\", \"Train subset became single-class; some metrics (AUC) may be undefined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaa3762",
   "metadata": {},
   "source": [
    "# Cell 4 ‚Äî VQC helpers (statevector + MC noisy variant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b1e0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statevector VQC (clean + Monte Carlo noisy variants) for probability estimation\n",
    "\n",
    "def _make_sv_device():\n",
    "    try:\n",
    "        dev = qml.device(\"lightning.qubit\", wires=D, shots=None)\n",
    "        J.log(\"device\", \"ok\", f\"Using lightning.qubit for VQC (D={D})\")\n",
    "        return dev\n",
    "    except Exception as e:\n",
    "        J.log(\"device\", \"warn\", f\"lightning.qubit unavailable ({e}); falling back to default.qubit\")\n",
    "        return qml.device(\"default.qubit\",  wires=D, shots=None)\n",
    "\n",
    "def _vqc_layer_clean(x, w):\n",
    "    qml.AngleEmbedding(x, wires=range(D), rotation=\"Y\")\n",
    "    BasicEntanglerLayers(w[None, :], wires=range(D))\n",
    "\n",
    "_dev_vqc = _make_sv_device()\n",
    "\n",
    "@qml.qnode(_dev_vqc, interface=None)\n",
    "def _vqc_clean(x, weights):\n",
    "    for l in range(weights.shape[0]):\n",
    "        _vqc_layer_clean(x, weights[l])\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "# Monte Carlo noise mask sampling (Pauli + bit flips)\n",
    "def _sample_noise_masks(rng, pflip, pdepol):\n",
    "    flips = (rng.random(D) < pflip).astype(np.int8)\n",
    "    pa = np.zeros(D, dtype=np.int8)\n",
    "    mask = rng.random(D) < pdepol\n",
    "    if mask.any():\n",
    "        pa[mask] = rng.integers(1, 4, size=int(mask.sum()))  # 1:X,2:Y,3:Z\n",
    "    return flips, pa\n",
    "\n",
    "def _apply_noise(pa, flips):\n",
    "    for i in range(D):\n",
    "        lab = int(pa[i])\n",
    "        if lab == 1: qml.PauliX(i)\n",
    "        elif lab == 2: qml.PauliY(i)\n",
    "        elif lab == 3: qml.PauliZ(i)\n",
    "    if flips.any():\n",
    "        for i in range(D):\n",
    "            if flips[i]: qml.PauliX(i)\n",
    "\n",
    "@qml.qnode(_dev_vqc, interface=None)\n",
    "def _vqc_noisy_once(x, weights, flips, pa):\n",
    "    for l in range(weights.shape[0]):\n",
    "        qml.AngleEmbedding(x, wires=range(D), rotation=\"Y\")\n",
    "        _apply_noise(pa, flips)  # Insert noise between data re-upload and entangling layer\n",
    "        BasicEntanglerLayers(weights[l][None, :], wires=range(D))\n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd933fd",
   "metadata": {},
   "source": [
    "# Cell 5 ‚Äî Load trained VQC weights (from notebook 04; log if missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749d6f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained VQC weights produced in notebook 04 (required for reuse in robustness study)\n",
    "W_PATH = RESULTS / \"vqc_weights.npy\"\n",
    "if not W_PATH.exists():\n",
    "    J.log(\"weights\", \"fail\", \"Missing vqc_weights.npy (run 04_quantum_vqc.ipynb first).\")\n",
    "    raise FileNotFoundError(\"Run 04_quantum_vqc.ipynb first to save weights.\")\n",
    "weights = pnp.array(np.load(W_PATH), requires_grad=False)\n",
    "J.log(\"weights\", \"ok\", f\"Loaded VQC weights with shape {weights.shape}\")\n",
    "weights.shape  # (L, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6299fe",
   "metadata": {},
   "source": [
    "# Cell 6 ‚Äî VQC predict & full metrics (incl. PR-AUC, Spec, MCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b3fd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate VQC probabilities under optional Pauli + bit-flip noise via light MC sampling; derive split metrics\n",
    "def vqc_predict_proba(X, weights, pflip=0.0, pdepol=0.0, shots=0):\n",
    "    w = np.asarray(weights, dtype=float)\n",
    "    rng = np.random.default_rng(123)\n",
    "    out = []\n",
    "\n",
    "    if pflip == 0.0 and pdepol == 0.0:  # Pure path\n",
    "        for xi in X:\n",
    "            m = float(_vqc_clean(xi, w))\n",
    "            out.append((1.0 + m)/2.0)\n",
    "    else:  # Monte Carlo noisy approximation\n",
    "        S = max(16, shots // 32) if shots else 32\n",
    "        for xi in X:\n",
    "            acc = 0.0\n",
    "            for _ in range(S):\n",
    "                flips, pa = _sample_noise_masks(rng, pflip, pdepol)\n",
    "                m = float(_vqc_noisy_once(xi, w, flips, pa))\n",
    "                acc += (1.0 + m)/2.0\n",
    "            out.append(acc / S)\n",
    "\n",
    "    return np.clip(np.array(out, dtype=float), 1e-6, 1.0-1e-6)\n",
    "\n",
    "def extended_metrics_from_probs(p, y, split, thr=0.5):\n",
    "    \"\"\"Extended metrics + confusion matrix, with guards for undefined AUC.\"\"\"\n",
    "    yhat = (p >= thr).astype(int)\n",
    "    acc = accuracy_score(y, yhat)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y, yhat, average=\"binary\", zero_division=0)\n",
    "    try:\n",
    "        auc = roc_auc_score(y, p)\n",
    "    except ValueError:\n",
    "        auc = float(\"nan\")\n",
    "    try:\n",
    "        ap = average_precision_score(y, p)\n",
    "    except Exception:\n",
    "        ap = float(\"nan\")\n",
    "    cm = confusion_matrix(y, yhat, labels=[0,1])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    tnr = tn / (tn + fp) if (tn + fp) else float(\"nan\")            # Specificity\n",
    "    bal = balanced_accuracy_score(y, yhat)\n",
    "    mcc = matthews_corrcoef(y, yhat) if len(np.unique(y)) == 2 else float(\"nan\")\n",
    "    rep = classification_report(y, yhat, output_dict=True, zero_division=0)\n",
    "    return (\n",
    "        dict(split=split, acc=acc, prec=prec, rec=rec, f1=f1, auc=auc,\n",
    "             pr_auc=ap, balanced_acc=bal, specificity=tnr, mcc=mcc, thr=thr),\n",
    "        cm,\n",
    "        rep\n",
    "    )\n",
    "\n",
    "def save_cm_csv(cm, out_csv, normalized=False):\n",
    "    arr = cm.astype(np.float64)\n",
    "    if normalized:\n",
    "        rs = arr.sum(axis=1, keepdims=True)\n",
    "        arr = np.divide(arr, np.where(rs == 0, 1, rs))\n",
    "    df = pd.DataFrame(arr, index=[\"true_0\",\"true_1\"], columns=[\"pred_0\",\"pred_1\"])\n",
    "    df.to_csv(out_csv, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f19632e",
   "metadata": {},
   "source": [
    "# Cell 7 ‚Äî Kernel helpers (pure + MC adjoint) & Nystr√∂m utilities (readable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00456775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantum kernel helper functions: pure (state overlap) and noisy (MC state sampling) + Nystr√∂m utilities\n",
    "\n",
    "def _entangle_ring(ws):\n",
    "    N = len(ws)\n",
    "    for i in range(N):\n",
    "        qml.CZ(wires=[ws[i], ws[(i+1)%N]])\n",
    "\n",
    "def save_npz(path, **arrays): np.savez_compressed(path, **arrays)\n",
    "def load_npz(path): return dict(np.load(path, allow_pickle=True)) if Path(path).exists() else None\n",
    "\n",
    "def normalize_block(K, da, db):\n",
    "    da = np.where(da <= 1e-12, 1e-12, da)\n",
    "    db = np.where(db <= 1e-12, 1e-12, db)\n",
    "    return np.clip(K, 0.0, 1.0) / (np.sqrt(np.outer(da, db)) + 1e-12)\n",
    "\n",
    "# Pure (noiseless) kernel via explicit state construction + amplitude inner products\n",
    "def make_pure_state_getter():\n",
    "    try:\n",
    "        dev = qml.device(\"lightning.qubit\", wires=D, shots=None)\n",
    "        J.log(\"device\", \"ok\", f\"Using lightning.qubit for pure-kernel states (D={D})\")\n",
    "    except Exception as e:\n",
    "        J.log(\"device\", \"warn\", f\"lightning.qubit unavailable ({e}); fallback to default.qubit\")\n",
    "        dev = qml.device(\"default.qubit\", wires=D, shots=None)\n",
    "\n",
    "    @qml.qnode(dev)\n",
    "    def phi(x):\n",
    "        qml.AngleEmbedding(x, wires=range(D), rotation=\"Y\")\n",
    "        _entangle_ring(list(range(D)))\n",
    "        return qml.state()\n",
    "    return phi\n",
    "\n",
    "def states_batch(X, get_state, dtype=np.complex64):\n",
    "    return np.stack([get_state(x) for x in X]).astype(dtype, copy=False)\n",
    "\n",
    "def kernel_from_states(SA, SB):\n",
    "    M = SA @ SB.conj().T\n",
    "    return np.abs(M)**2\n",
    "\n",
    "# Noisy kernel estimation using pairwise independent noise masks (MC averaged)\n",
    "def _noise_masks(rng, pflip, pdepol):\n",
    "    flips = (rng.random(D) < pflip).astype(np.int8)\n",
    "    pa = np.zeros(D, dtype=np.int8)\n",
    "    mask = rng.random(D) < pdepol\n",
    "    if mask.any():\n",
    "        pa[mask] = rng.integers(1, 4, size=int(mask.sum()))\n",
    "    return flips, pa\n",
    "\n",
    "def _build_noisy_state_qnode():\n",
    "    try:\n",
    "        dev = qml.device(\"lightning.qubit\", wires=D, shots=None)\n",
    "    except Exception:\n",
    "        dev = qml.device(\"default.qubit\", wires=D, shots=None)\n",
    "\n",
    "    def _apply(pa, flips):\n",
    "        for i in range(D):\n",
    "            lab = int(pa[i])\n",
    "            if lab == 1: qml.PauliX(i)\n",
    "            elif lab == 2: qml.PauliY(i)\n",
    "            elif lab == 3: qml.PauliZ(i)\n",
    "        if flips.any():\n",
    "            for i in range(D):\n",
    "                if flips[i]: qml.PauliX(i)\n",
    "\n",
    "    @qml.qnode(dev)\n",
    "    def psi(x, flips, pa):\n",
    "        qml.AngleEmbedding(x, wires=range(D), rotation=\"Y\")\n",
    "        _apply(pa, flips)  # pre-entangle\n",
    "        _entangle_ring(list(range(D)))\n",
    "        _apply(pa, flips)  # post-entangle\n",
    "        return qml.state()\n",
    "    return psi\n",
    "\n",
    "def _states_noise_batch(X, flips, pa, psi):\n",
    "    return np.stack([psi(x, flips, pa) for x in X]).astype(np.complex64, copy=False)\n",
    "\n",
    "def mc_blocks_via_states(Xtr_s, Xva, Xte, A, pflip, pdepol, S=24, seed=123):\n",
    "    \"\"\"Monte Carlo average of kernel blocks using independent left/right noise masks.\"\"\"\n",
    "    psi = _build_noisy_state_qnode()\n",
    "    rng = np.random.default_rng(seed)\n",
    "    M = len(A)\n",
    "\n",
    "    K_MM = np.zeros((M, M), dtype=float)\n",
    "    K_trM = np.zeros((len(Xtr_s), M), dtype=float)\n",
    "    K_vaM = np.zeros((len(Xva),   M), dtype=float)\n",
    "    K_teM = np.zeros((len(Xte),   M), dtype=float)\n",
    "    d_M  = np.zeros(M, dtype=float)\n",
    "    d_tr = np.zeros(len(Xtr_s), dtype=float)\n",
    "    d_va = np.zeros(len(Xva),   dtype=float)\n",
    "    d_te = np.zeros(len(Xte),   dtype=float)\n",
    "\n",
    "    for _ in range(S):\n",
    "        flipsL, paL = _noise_masks(rng, pflip, pdepol)\n",
    "        flipsR, paR = _noise_masks(rng, pflip, pdepol)\n",
    "\n",
    "        A_L   = _states_noise_batch(A,     flipsL, paL, psi)\n",
    "        A_R   = _states_noise_batch(A,     flipsR, paR, psi)\n",
    "        tr_L  = _states_noise_batch(Xtr_s, flipsL, paL, psi)\n",
    "        tr_R  = _states_noise_batch(Xtr_s, flipsR, paR, psi)\n",
    "        va_L  = _states_noise_batch(Xva,   flipsL, paL, psi)\n",
    "        va_R  = _states_noise_batch(Xva,   flipsR, paR, psi)\n",
    "        te_L  = _states_noise_batch(Xte,   flipsL, paL, psi)\n",
    "        te_R  = _states_noise_batch(Xte,   flipsR, paR, psi)\n",
    "\n",
    "        K_MM  += np.abs(A_L  @ A_R.conj().T)**2\n",
    "        K_trM += np.abs(tr_L @ A_R.conj().T)**2\n",
    "        K_vaM += np.abs(va_L @ A_R.conj().T)**2\n",
    "        K_teM += np.abs(te_L @ A_R.conj().T)**2\n",
    "\n",
    "        d_M  += np.abs(np.sum(A_L  * A_R.conj(), axis=1))**2\n",
    "        d_tr += np.abs(np.sum(tr_L * tr_R.conj(), axis=1))**2\n",
    "        d_va += np.abs(np.sum(va_L * va_R.conj(), axis=1))**2\n",
    "        d_te += np.abs(np.sum(te_L * te_R.conj(), axis=1))**2\n",
    "\n",
    "    invS = 1.0/float(S)\n",
    "    return (K_MM*invS, K_trM*invS, K_vaM*invS, K_teM*invS,\n",
    "            d_M*invS,   d_tr*invS,  d_va*invS,  d_te*invS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b7d8c4",
   "metadata": {},
   "source": [
    "# Cell 8 ‚Äî VQC sweep (timed; val-optimal threshold; full metrics; CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1449f358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweep VQC under varying noise + shot configurations; collect split metrics with timing\n",
    "def plot_roc(y_true, y_prob, title, out_png):\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    try:\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, label=f\"AUC={roc_auc:.3f}\")\n",
    "        plt.plot([0,1],[0,1], linestyle=\"--\")\n",
    "        plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(title); plt.legend(loc=\"lower right\"); plt.tight_layout()\n",
    "        plt.savefig(out_png, dpi=150); plt.close()\n",
    "    except Exception as e:\n",
    "        J.log(\"plot\", \"warn\", f\"VQC ROC plot skipped: {e}\")\n",
    "\n",
    "def plot_pr(y_true, y_prob, title, out_png):\n",
    "    from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "    try:\n",
    "        prec, rec, _ = precision_recall_curve(y_true, y_prob)\n",
    "        ap = average_precision_score(y_true, y_prob)\n",
    "        plt.figure()\n",
    "        plt.plot(rec, prec, label=f\"AP={ap:.3f}\")\n",
    "        plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(title); plt.legend(loc=\"lower left\"); plt.tight_layout()\n",
    "        plt.savefig(out_png, dpi=150); plt.close()\n",
    "    except Exception as e:\n",
    "        J.log(\"plot\", \"warn\", f\"VQC PR plot skipped: {e}\")\n",
    "\n",
    "timer_v = PhaseTimer()\n",
    "rows = []\n",
    "\n",
    "with timer_v.timed(f\"VQC_sweep_total_{len(SWEEP)}\"):\n",
    "    for shots, pflip, pdepol in SWEEP:\n",
    "        cfg = f\"shots={shots}, pflip={pflip}, pdepol={pdepol}\"\n",
    "        with timer_v.timed(f\"VQC_forward_{shots}_{pflip}_{pdepol}\"):\n",
    "            p_tr = vqc_predict_proba(Xtr, weights, pflip=pflip, pdepol=pdepol, shots=shots)\n",
    "            p_va = vqc_predict_proba(Xva, weights, pflip=pflip, pdepol=pdepol, shots=shots)\n",
    "            p_te = vqc_predict_proba(Xte, weights, pflip=pflip, pdepol=pdepol, shots=shots)\n",
    "\n",
    "        with timer_v.timed(f\"VQC_metrics_{shots}_{pflip}_{pdepol}\"):\n",
    "            # Fix threshold=0.5 for robustness comparability in sweeps\n",
    "            m_tr, cm_tr, rep_tr = extended_metrics_from_probs(p_tr, ytr, \"train\", thr=0.5)\n",
    "            m_va, cm_va, rep_va = extended_metrics_from_probs(p_va, yva, \"val\",   thr=0.5)\n",
    "            m_te, cm_te, rep_te = extended_metrics_from_probs(p_te, yte, \"test\",  thr=0.5)\n",
    "\n",
    "            # Annotate and collect\n",
    "            for m in (m_tr, m_va, m_te):\n",
    "                m.update(dict(model=\"VQC\", shots=shots, pflip=pflip, pdepol=pdepol))\n",
    "                rows.append(m)\n",
    "\n",
    "            # Save confusion matrices per config\n",
    "            tag = f\"vqc_{shots}_{str(pflip).replace('.','p')}_{str(pdepol).replace('.','p')}\"\n",
    "            save_cm_csv(cm_tr, RESULTS/f\"metrics/cm_{tag}_train.csv\", normalized=False)\n",
    "            save_cm_csv(cm_tr, RESULTS/f\"metrics/cm_{tag}_train_norm.csv\", normalized=True)\n",
    "            save_cm_csv(cm_va, RESULTS/f\"metrics/cm_{tag}_val.csv\",   normalized=False)\n",
    "            save_cm_csv(cm_va, RESULTS/f\"metrics/cm_{tag}_val_norm.csv\",   normalized=True)\n",
    "            save_cm_csv(cm_te, RESULTS/f\"metrics/cm_{tag}_test.csv\",  normalized=False)\n",
    "            save_cm_csv(cm_te, RESULTS/f\"metrics/cm_{tag}_test_norm.csv\",  normalized=True)\n",
    "\n",
    "            # Plots (test) per config\n",
    "            plot_roc(yte, p_te, f\"VQC ROC ({cfg})\", RESULTS/f\"plots/{tag}_roc_test.png\")\n",
    "            plot_pr (yte, p_te, f\"VQC PR  ({cfg})\", RESULTS/f\"plots/{tag}_pr_test.png\")\n",
    "\n",
    "df_vqc = pd.DataFrame(rows)\n",
    "df_vqc.to_csv(RESULTS/\"metrics/noise_sweep_vqc.csv\", index=False)\n",
    "print(\"VQC sweep rows:\", len(df_vqc))\n",
    "display(df_vqc.head())\n",
    "J.log(\"vqc_sweep\", \"ok\", f\"Completed VQC sweep; rows={len(df_vqc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cef63b4",
   "metadata": {},
   "source": [
    "# Cell 9 ‚Äî QSVM sweep (pure cached + MC noisy Nystr√∂m; val-optimal threshold; CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56b1d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QSVM robustness sweep: reuse cached pure kernel or build via states; approximate noisy kernels via Nystr√∂m\n",
    "from numpy.linalg import eigh\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix,\n",
    "    balanced_accuracy_score, matthews_corrcoef, classification_report, average_precision_score,\n",
    "    precision_recall_curve, roc_curve, auc\n",
    ")\n",
    "\n",
    "rows = []\n",
    "timer_q = PhaseTimer()\n",
    "\n",
    "# ---------- helpers: shapes & alignment ----------\n",
    "def _fix_precomputed_shape(K, n_train, name=\"K\"):\n",
    "    \"\"\"Ensure precomputed kernel has shape (n_rows, n_train). Transpose/reshape if needed.\"\"\"\n",
    "    K = np.asarray(K)\n",
    "    if K.ndim == 1:\n",
    "        if K.size % n_train != 0:\n",
    "            raise ValueError(f\"{name}: 1D kernel of size {K.size} not divisible by n_train={n_train}\")\n",
    "        K = K.reshape(-1, n_train)\n",
    "    elif K.ndim > 2:\n",
    "        if K.size % n_train != 0:\n",
    "            raise ValueError(f\"{name}: ND kernel with total size {K.size} not divisible by n_train={n_train}\")\n",
    "        K = K.reshape(-1, n_train)\n",
    "    if K.shape[1] != n_train and K.shape[0] == n_train:\n",
    "        K = K.T\n",
    "    if K.shape[1] != n_train:\n",
    "        raise ValueError(f\"{name}: bad shape {K.shape}; expected (*, {n_train})\")\n",
    "    return K\n",
    "\n",
    "def _align_split_lengths(y_true, n_rows, split_name, tag):\n",
    "    \"\"\"\n",
    "    Make y_true length match n_rows (kernel rows / feature rows).\n",
    "    If longer, head-slice; if shorter, raise (we cannot create labels).\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true).reshape(-1)\n",
    "    if len(y_true) == n_rows:\n",
    "        return y_true\n",
    "    if len(y_true) > n_rows:\n",
    "        if 'J' in globals():\n",
    "            J.log(\"align\", \"warn\",\n",
    "                  f\"{tag}:{split_name} y length {len(y_true)} > kernel rows {n_rows}; slicing to head {n_rows}.\")\n",
    "        print(f\"‚ö†Ô∏è  [{tag}::{split_name}] y length {len(y_true)} > rows {n_rows}; slicing y -> {n_rows}\")\n",
    "        return y_true[:n_rows]\n",
    "    # len(y_true) < n_rows\n",
    "    raise ValueError(f\"{tag}:{split_name} has fewer labels ({len(y_true)}) than rows ({n_rows}). \"\n",
    "                     f\"Cannot align by truncating kernel safely. Regenerate kernels or use consistent splits.\")\n",
    "\n",
    "def _plot_roc_pr(y_true, prob, tag_prefix):\n",
    "    try:\n",
    "        fpr, tpr, _ = roc_curve(y_true, prob); roc_auc = auc(fpr, tpr)\n",
    "        plt.figure(); plt.plot(fpr, tpr, label=f\"AUC={roc_auc:.3f}\")\n",
    "        plt.plot([0,1],[0,1],\"--\",lw=1); plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(f\"QSVM ROC ‚Äî {tag_prefix}\")\n",
    "        plt.legend(); plt.tight_layout(); plt.savefig(RESULTS/f\"plots/{tag_prefix}_roc_test.png\", dpi=150); plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è ROC plot skipped ({tag_prefix}): {e}\")\n",
    "        if 'J' in globals(): J.log(\"plot\",\"warn\",f\"ROC skipped {tag_prefix}: {e}\")\n",
    "    try:\n",
    "        prec, rec, _ = precision_recall_curve(y_true, prob); ap = average_precision_score(y_true, prob)\n",
    "        plt.figure(); plt.plot(rec, prec, label=f\"AP={ap:.3f}\")\n",
    "        plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(f\"QSVM PR ‚Äî {tag_prefix}\")\n",
    "        plt.legend(); plt.tight_layout(); plt.savefig(RESULTS/f\"plots/{tag_prefix}_pr_test.png\", dpi=150); plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è PR plot skipped ({tag_prefix}): {e}\")\n",
    "        if 'J' in globals(): J.log(\"plot\",\"warn\",f\"PR skipped {tag_prefix}: {e}\")\n",
    "\n",
    "def _save_probs(tag_prefix, prob_tr=None, prob_va=None, prob_te=None):\n",
    "    outdir = RESULTS / \"metrics\"; outdir.mkdir(parents=True, exist_ok=True)\n",
    "    if prob_tr is not None: np.save(outdir / f\"qsvm_{tag_prefix}_probs_train.npy\", prob_tr)\n",
    "    if prob_va is not None: np.save(outdir / f\"qsvm_{tag_prefix}_probs_val.npy\",   prob_va)\n",
    "    if prob_te is not None: np.save(outdir / f\"qsvm_{tag_prefix}_probs_test.npy\",  prob_te)\n",
    "\n",
    "def ext_metrics_from_scores(prob, y, split):\n",
    "    \"\"\"Return extended metrics dict (thr=0.5) and confusion matrix/report.\"\"\"\n",
    "    prob = np.clip(np.asarray(prob).reshape(-1), 1e-6, 1-1e-6)\n",
    "    pred = (prob >= 0.5).astype(int)\n",
    "    acc = accuracy_score(y, pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y, pred, average=\"binary\", zero_division=0)\n",
    "    try: auc_v = roc_auc_score(y, prob)\n",
    "    except ValueError: auc_v = float(\"nan\")\n",
    "    try: ap = average_precision_score(y, prob)\n",
    "    except Exception: ap = float(\"nan\")\n",
    "    cm = confusion_matrix(y, pred, labels=[0,1])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    tnr = tn / (tn + fp) if (tn + fp) else float(\"nan\")\n",
    "    bal = balanced_accuracy_score(y, pred)\n",
    "    mcc = matthews_corrcoef(y, pred) if len(np.unique(y)) == 2 else float(\"nan\")\n",
    "    rep = classification_report(y, pred, output_dict=True, zero_division=0)\n",
    "    return dict(split=split, acc=acc, prec=prec, rec=rec, f1=f1, auc=auc_v,\n",
    "                pr_auc=ap, balanced_acc=bal, specificity=tnr, mcc=mcc, thr=0.5), cm, rep\n",
    "\n",
    "# ---------- cache fingerprint for noiseless kernels ----------\n",
    "fp = f\"D{D}_N{len(Xtr_s)}_pca17_scaler\"\n",
    "PURE_KERNELS_FILE = RESULTS / f\"cache/pure_kernels_{fp}.npz\"\n",
    "\n",
    "pure_cached = load_npz(PURE_KERNELS_FILE)\n",
    "if pure_cached:\n",
    "    K_trtr_n = pure_cached[\"K_trtr_n\"]; K_vatr_n = pure_cached[\"K_vatr_n\"]; K_tetr_n = pure_cached[\"K_tetr_n\"]\n",
    "    print(\"Loaded pure kernels from cache.\")\n",
    "    J.log(\"kernel_cache\", \"ok\", f\"Loaded cached pure kernels {PURE_KERNELS_FILE.name}\")\n",
    "else:\n",
    "    K_trtr_n = K_vatr_n = K_tetr_n = None\n",
    "    J.log(\"kernel_cache\", \"warn\", \"Pure kernels not in cache; will compute on demand.\")\n",
    "\n",
    "with timer_q.timed(f\"QSVM_sweep_total_{len(SWEEP)}\"):\n",
    "    for shots, pflip, pdepol in SWEEP:\n",
    "        print(f\"\\n[QSVM] shots={shots}, pflip={pflip}, pdepol={pdepol}\")\n",
    "        noiseless = (pflip == 0.0 and pdepol == 0.0)\n",
    "\n",
    "        if noiseless:\n",
    "            # Build or load pure kernels\n",
    "            if K_trtr_n is None:\n",
    "                with timer_q.timed(\"pure_states_and_gram\"):\n",
    "                    get_state = make_pure_state_getter()\n",
    "                    S_tr = states_batch(Xtr_s, get_state)\n",
    "                    S_va = states_batch(Xva,   get_state)\n",
    "                    S_te = states_batch(Xte,   get_state)\n",
    "                    K_trtr = kernel_from_states(S_tr, S_tr)\n",
    "                    K_vatr = kernel_from_states(S_va, S_tr)\n",
    "                    K_tetr = kernel_from_states(S_te, S_tr)\n",
    "                d_tr = np.clip(np.diag(K_trtr), 1e-12, 1.0)\n",
    "                d_va = np.clip(np.diag(kernel_from_states(S_va, S_va)), 1e-12, 1.0)\n",
    "                d_te = np.clip(np.diag(kernel_from_states(S_te, S_te)), 1e-12, 1.0)\n",
    "                with timer_q.timed(\"pure_normalize\"):\n",
    "                    K_trtr_n = normalize_block(0.5*(K_trtr + K_trtr.T), d_tr, d_tr) + 1e-8*np.eye(len(d_tr))\n",
    "                    K_vatr_n = normalize_block(K_vatr, d_va, d_tr)\n",
    "                    K_tetr_n = normalize_block(K_tetr, d_te, d_tr)\n",
    "                save_npz(PURE_KERNELS_FILE, K_trtr_n=K_trtr_n, K_vatr_n=K_vatr_n, K_tetr_n=K_tetr_n)\n",
    "                print(\"Saved pure kernels to cache.\")\n",
    "                J.log(\"kernel_cache\", \"ok\", f\"Saved pure kernels -> {PURE_KERNELS_FILE.name}\")\n",
    "\n",
    "            if np.unique(ytr_s).size < 2:\n",
    "                J.log(\"limitation\", \"warn\", \"Skip pure QSVM branch ‚Äî single-class training slice.\")\n",
    "            else:\n",
    "                # Fit\n",
    "                with timer_q.timed(\"pure_svc_fit\"):\n",
    "                    K_trtr_n_fixed = _fix_precomputed_shape(K_trtr_n, K_trtr_n.shape[0], \"K_trtr_n\")\n",
    "                    clf = SVC(C=5.0, kernel=\"precomputed\", probability=True, class_weight=\"balanced\", random_state=0)\n",
    "                    clf.fit(K_trtr_n_fixed, ytr_s)\n",
    "\n",
    "                # Evaluate splits\n",
    "                def evalK(K, y_true, split, tag):\n",
    "                    K_fixed = _fix_precomputed_shape(K, K_trtr_n.shape[0], f\"{tag}:{split}\")\n",
    "                    print(f\"   shapes -> K:{K_fixed.shape}, y_in:{y_true.shape}\", flush=True)\n",
    "                    # align y to kernel rows if needed\n",
    "                    y_use = _align_split_lengths(y_true, K_fixed.shape[0], split, tag)\n",
    "                    t0 = time.perf_counter()\n",
    "                    try:\n",
    "                        prob = clf.predict_proba(K_fixed)[:, 1]\n",
    "                    except Exception:\n",
    "                        df = clf.decision_function(K_fixed); prob = 1.0/(1.0+np.exp(-df))\n",
    "                    prob = np.asarray(prob).reshape(-1)\n",
    "                    # If we had to slice y, slice probs as well to keep parity\n",
    "                    if prob.shape[0] != y_use.shape[0]:\n",
    "                        n = min(prob.shape[0], y_use.shape[0])\n",
    "                        if 'J' in globals():\n",
    "                            J.log(\"align\", \"warn\",\n",
    "                                  f\"{tag}:{split} prob len {prob.shape[0]} != y {y_use.shape[0]}; truncating both to {n}.\")\n",
    "                        print(f\"‚ö†Ô∏è  [{tag}::{split}] prob {prob.shape[0]} != y {y_use.shape[0]}; trunc -> {n}\")\n",
    "                        prob = prob[:n]; y_use = y_use[:n]\n",
    "                    m, cm, rep = ext_metrics_from_scores(prob, y_use, split)\n",
    "                    save_cm_csv(cm, RESULTS/f\"metrics/cm_qsvm_{tag}_{split}.csv\", normalized=False)\n",
    "                    save_cm_csv(cm, RESULTS/f\"metrics/cm_qsvm_{tag}_{split}_norm.csv\", normalized=True)\n",
    "                    timer_q.add(f\"pure_eval_{split}\", time.perf_counter()-t0)\n",
    "                    print(f\"  [{tag}::{split}] F1={m['f1']:.3f}, AUC={m['auc']:.3f}, PR-AUC={m['pr_auc']:.3f}, ACC={m['acc']:.3f}\")\n",
    "                    return m, prob\n",
    "\n",
    "                tag = f\"pure_{shots}_{str(pflip).replace('.','p')}_{str(pdepol).replace('.','p')}\"\n",
    "                m_tr, prob_tr = evalK(K_trtr_n, ytr_s, \"train\", tag)\n",
    "                m_va, prob_va = evalK(K_vatr_n, yva,   \"val\",   tag)\n",
    "                m_te, prob_te = evalK(K_tetr_n, yte,   \"test\",  tag)\n",
    "\n",
    "                rows += [\n",
    "                    {**m_tr, \"model\":\"QSVM\", \"shots\":shots, \"pflip\":pflip, \"pdepol\":pdepol},\n",
    "                    {**m_va, \"model\":\"QSVM\", \"shots\":shots, \"pflip\":pflip, \"pdepol\":pdepol},\n",
    "                    {**m_te, \"model\":\"QSVM\", \"shots\":shots, \"pflip\":pflip, \"pdepol\":pdepol},\n",
    "                ]\n",
    "                _save_probs(tag, prob_tr, prob_va, prob_te)\n",
    "                _plot_roc_pr(yte, prob_te, f\"qsvm_{tag}\")\n",
    "\n",
    "        else:\n",
    "            # Noisy Nystr√∂m approximation\n",
    "            S_NOISE = max(16, shots // 32) or 16\n",
    "            rng = np.random.default_rng(123)\n",
    "            idx_anchor = rng.choice(len(Xtr_s), size=min(M_ANCHORS, len(Xtr_s)), replace=False)\n",
    "            A = Xtr_s[idx_anchor]\n",
    "\n",
    "            with timer_q.timed(\"noisy_blocks_states\"):\n",
    "                K_MM, K_trM, K_vaM, K_teM, d_M, d_tr, d_va, d_te = mc_blocks_via_states(\n",
    "                    Xtr_s, Xva, Xte, A, pflip, pdepol, S=S_NOISE, seed=123\n",
    "                )\n",
    "            with timer_q.timed(\"noisy_normalize\"):\n",
    "                def norm(K, da, db):\n",
    "                    da = np.where(da <= 1e-12, 1e-12, da)\n",
    "                    db = np.where(db <= 1e-12, 1e-12, db)\n",
    "                    return np.clip(K, 0.0, 1.0) / (np.sqrt(np.outer(da, db)) + 1e-12)\n",
    "                K_MM_n  = norm(0.5*(K_MM + K_MM.T), d_M, d_M) + 1e-8*np.eye(len(d_M))\n",
    "                K_trM_n = norm(K_trM, d_tr, d_M)\n",
    "                K_vaM_n = norm(K_vaM, d_va, d_M)\n",
    "                K_teM_n = norm(K_teM, d_te, d_M)\n",
    "\n",
    "            with timer_q.timed(\"noisy_features\"):\n",
    "                w, V = eigh(K_MM_n)\n",
    "                Winv_sqrt = V @ np.diag(1.0/np.sqrt(np.clip(w + 1e-6, 1e-12, None))) @ V.T\n",
    "                Phi_tr = K_trM_n @ Winv_sqrt\n",
    "                Phi_va = K_vaM_n @ Winv_sqrt\n",
    "                Phi_te = K_teM_n @ Winv_sqrt\n",
    "\n",
    "            if np.unique(ytr_s).size < 2:\n",
    "                J.log(\"limitation\", \"warn\", \"Skip noisy QSVM branch ‚Äî single-class training slice.\")\n",
    "            else:\n",
    "                with timer_q.timed(\"noisy_linear_svc_fit\"):\n",
    "                    clf = SVC(C=5.0, kernel=\"linear\", probability=True, class_weight=\"balanced\", random_state=0)\n",
    "                    clf.fit(Phi_tr, ytr_s)\n",
    "\n",
    "                def eval_feat(F, y_true, split, tag):\n",
    "                    print(f\"   shapes -> Œ¶:{F.shape}, y_in:{y_true.shape}\", flush=True)\n",
    "                    y_use = _align_split_lengths(y_true, F.shape[0], split, tag)\n",
    "                    t0 = time.perf_counter()\n",
    "                    try:\n",
    "                        prob = clf.predict_proba(F)[:, 1]\n",
    "                    except Exception:\n",
    "                        df = clf.decision_function(F); prob = 1.0/(1.0+np.exp(-df))\n",
    "                    prob = np.asarray(prob).reshape(-1)\n",
    "                    if prob.shape[0] != y_use.shape[0]:\n",
    "                        n = min(prob.shape[0], y_use.shape[0])\n",
    "                        if 'J' in globals():\n",
    "                            J.log(\"align\", \"warn\",\n",
    "                                  f\"{tag}:{split} prob len {prob.shape[0]} != y {y_use.shape[0]}; truncating both to {n}.\")\n",
    "                        print(f\"‚ö†Ô∏è  [{tag}::{split}] prob {prob.shape[0]} != y {y_use.shape[0]}; trunc -> {n}\")\n",
    "                        prob = prob[:n]; y_use = y_use[:n]\n",
    "                    m, cm, rep = ext_metrics_from_scores(prob, y_use, split)\n",
    "                    save_cm_csv(cm, RESULTS/f\"metrics/cm_qsvm_{tag}_{split}.csv\", normalized=False)\n",
    "                    save_cm_csv(cm, RESULTS/f\"metrics/cm_qsvm_{tag}_{split}_norm.csv\", normalized=True)\n",
    "                    timer_q.add(f\"noisy_eval_{split}\", time.perf_counter()-t0)\n",
    "                    print(f\"  [{tag}::{split}] F1={m['f1']:.3f}, AUC={m['auc']:.3f}, PR-AUC={m['pr_auc']:.3f}, ACC={m['acc']:.3f}\")\n",
    "                    return m, prob\n",
    "\n",
    "                tag = f\"noisy_{shots}_{str(pflip).replace('.','p')}_{str(pdepol).replace('.','p')}_A{len(A)}_S{S_NOISE}\"\n",
    "                m_tr, prob_tr = eval_feat(Phi_tr, ytr_s, \"train\", tag)\n",
    "                m_va, prob_va = eval_feat(Phi_va, yva,   \"val\",   tag)\n",
    "                m_te, prob_te = eval_feat(Phi_te, yte,   \"test\",  tag)\n",
    "\n",
    "                rows += [\n",
    "                    {**m_tr, \"model\":\"QSVM\", \"shots\":shots, \"pflip\":pflip, \"pdepol\":pdepol, \"anchors\": int(len(A)), \"S_NOISE\": int(S_NOISE)},\n",
    "                    {**m_va, \"model\":\"QSVM\", \"shots\":shots, \"pflip\":pflip, \"pdepol\":pdepol, \"anchors\": int(len(A)), \"S_NOISE\": int(S_NOISE)},\n",
    "                    {**m_te, \"model\":\"QSVM\", \"shots\":shots, \"pflip\":pflip, \"pdepol\":pdepol, \"anchors\": int(len(A)), \"S_NOISE\": int(S_NOISE)},\n",
    "                ]\n",
    "                _save_probs(tag, prob_tr, prob_va, prob_te)\n",
    "                _plot_roc_pr(yte, prob_te, f\"qsvm_{tag}\")\n",
    "\n",
    "# finalize\n",
    "df_qsvm = pd.DataFrame(rows)\n",
    "df_qsvm.to_csv(RESULTS/\"metrics/noise_sweep_qsvm.csv\", index=False)\n",
    "print(\"QSVM sweep rows:\", len(df_qsvm)); display(df_qsvm.head())\n",
    "if 'J' in globals(): J.log(\"qsvm_sweep\", \"ok\", f\"Completed QSVM sweep; rows={len(df_qsvm)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eb189e",
   "metadata": {},
   "source": [
    "# Cell 10 ‚Äî pivots & JSON run report (with real timers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a91572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize test split performance; persist pivot tables and a JSON timing/config report\n",
    "METRICS_DIR = RESULTS / \"metrics\"\n",
    "\n",
    "# Pivots (test split only)\n",
    "if len(df_vqc) == 0 or len(df_qsvm) == 0:\n",
    "    J.log(\"summary\", \"warn\", \"One of the sweep frames is empty; pivots may be incomplete.\")\n",
    "pv_vqc  = (df_vqc[df_vqc[\"split\"]==\"test\"]\n",
    "           .pivot_table(index=[\"shots\",\"pflip\",\"pdepol\"], values=[\"f1\",\"auc\",\"acc\",\"pr_auc\",\"balanced_acc\",\"specificity\",\"mcc\"], aggfunc=\"mean\")\n",
    "           .sort_values(\"f1\", ascending=False))\n",
    "pv_qsvm = (df_qsvm[df_qsvm[\"split\"]==\"test\"]\n",
    "           .pivot_table(index=[\"shots\",\"pflip\",\"pdepol\"], values=[\"f1\",\"auc\",\"acc\",\"pr_auc\",\"balanced_acc\",\"specificity\",\"mcc\"], aggfunc=\"mean\")\n",
    "           .sort_values(\"f1\", ascending=False))\n",
    "\n",
    "pv_vqc.to_csv(METRICS_DIR/\"pivot_vqc_test.csv\")\n",
    "pv_qsvm.to_csv(METRICS_DIR/\"pivot_qsvm_test.csv\")\n",
    "\n",
    "# Run report with timers & configuration\n",
    "run_report = {\n",
    "    \"config\": {\n",
    "        \"D\": int(D), \"MAX_TR\": int(len(Xtr_s)), \"M_ANCHORS\": int(M_ANCHORS),\n",
    "        \"sweep_size\": int(len(SWEEP)),\n",
    "        \"shots_grid\": shots_grid, \"pflip_grid\": pflip_grid, \"pdepol_grid\": pdepol_grid,\n",
    "    },\n",
    "    \"timing\": {\n",
    "        \"VQC\": {k: pretty_seconds(v) for k,v in PhaseTimer().to_dict().items()},  # placeholder if not used\n",
    "        \"QSVM\": {k: pretty_seconds(v) for k,v in PhaseTimer().to_dict().items()}, # placeholder if not used\n",
    "        \"VQC_actual\": {k: pretty_seconds(v) for k,v in timer_v.to_dict().items()},\n",
    "        \"QSVM_actual\": {k: pretty_seconds(v) for k,v in timer_q.to_dict().items()},\n",
    "    }\n",
    "}\n",
    "with open(METRICS_DIR/\"noise_sweep_run_report.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(run_report, f, indent=2)\n",
    "\n",
    "print(\"\\n=== Run timing summary ===\")\n",
    "for k, v in timer_v.to_dict().items():\n",
    "    print(f\"VQC:{k:>30}  {pretty_seconds(v)}\")\n",
    "for k, v in timer_q.to_dict().items():\n",
    "    print(f\"QSVM:{k:>29}  {pretty_seconds(v)}\")\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(\" - results/metrics/noise_sweep_vqc.csv\")\n",
    "print(\" - results/metrics/noise_sweep_qsvm.csv\")\n",
    "print(\" - results/metrics/pivot_vqc_test.csv\")\n",
    "print(\" - results/metrics/pivot_qsvm_test.csv\")\n",
    "print(\" - results/metrics/noise_sweep_run_report.json\")\n",
    "\n",
    "# Journal: roll-up of warnings/failures\n",
    "issues = []\n",
    "for e in J.events:\n",
    "    if e[\"status\"] in (\"warn\",\"fail\"):\n",
    "        issues.append(f\"- [{e['step']}] {e['message']}\")\n",
    "rollup = \"No warnings or failures.\" if not issues else \"Issues observed:\\n\" + \"\\n\".join(issues)\n",
    "print(\"\\n=== RUN SUMMARY ===\\n\" + rollup)\n",
    "\n",
    "ts = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "J.save(RESULTS/\"logs\"/f\"noise_robustness_{ts}\")\n",
    "(RESULTS/\"logs\"/f\"noise_robustness_{ts}_summary.txt\").write_text(rollup, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
