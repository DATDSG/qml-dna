{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16568e51",
   "metadata": {},
   "source": [
    "# 03_quantum_kernel.ipynb ‚Äî QSVM (precomputed kernel)\n",
    "\n",
    "This notebook computes a quantum kernel (via PennyLane) on PCA‚Äëreduced k‚Äëmer features and trains an SVM with the precomputed Gram matrix. Execute sequentially: Cell 0 (perf env) -> Cell 1 ... Cell 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0726471c",
   "metadata": {},
   "source": [
    "# Cell 0 ‚Äî perf env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac0b0ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLAS threads: 8 8\n"
     ]
    }
   ],
   "source": [
    "# Normalize thread usage for reproducible classical linear algebra performance\n",
    "import os\n",
    "os.environ.setdefault(\"OMP_NUM_THREADS\", \"8\")\n",
    "os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"8\")\n",
    "os.environ.setdefault(\"MKL_NUM_THREADS\", \"8\")\n",
    "os.environ.setdefault(\"NUMEXPR_NUM_THREADS\", \"8\")\n",
    "print(\"BLAS threads:\", os.environ.get(\"OMP_NUM_THREADS\"), os.environ.get(\"OPENBLAS_NUM_THREADS\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05de0ea",
   "metadata": {},
   "source": [
    "# Cell 1 ‚Äî imports, paths, journaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5606192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports: classical preprocessing + PennyLane for quantum kernel construction\n",
    "from pathlib import Path\n",
    "import json, warnings, time, os\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pennylane as qml\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix,\n",
    "    classification_report, balanced_accuracy_score, matthews_corrcoef, average_precision_score\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "ROOT = Path(\".\")\n",
    "PROCESSED = ROOT / \"data\" / \"processed\"\n",
    "RESULTS = ROOT / \"results\"\n",
    "(RESULTS / \"kernels\").mkdir(parents=True, exist_ok=True)\n",
    "(RESULTS / \"metrics\").mkdir(parents=True, exist_ok=True)\n",
    "(RESULTS / \"plots\").mkdir(parents=True, exist_ok=True)\n",
    "(RESULTS / \"logs\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.random.seed(7)\n",
    "\n",
    "# ---- Run journal (for documentation) ----\n",
    "class RunJournal:\n",
    "    def __init__(self): self.events = []\n",
    "    def log(self, step, status, message, **extras):\n",
    "        self.events.append({\n",
    "            \"ts\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"step\": step, \"status\": status, \"message\": message, **extras\n",
    "        })\n",
    "        sym = \"‚úÖ\" if status==\"ok\" else (\"‚ö†Ô∏è\" if status==\"warn\" else \"‚ùå\")\n",
    "        print(f\"{sym} [{step}] {message}\")\n",
    "    def df(self): return pd.DataFrame(self.events)\n",
    "    def save(self, base: Path):\n",
    "        df = self.df()\n",
    "        md = [\"| ts | step | status | message |\", \"|---|---|---|---|\"]\n",
    "        for _,r in df.iterrows():\n",
    "            md.append(f\"| {r.ts} | {r.step} | {r.status} | {r.message} |\")\n",
    "        (base.with_suffix(\".md\")).write_text(\"\\n\".join(md), encoding=\"utf-8\")\n",
    "        (base.with_suffix(\".json\")).write_text(df.to_json(orient=\"records\", indent=2), encoding=\"utf-8\")\n",
    "        print(f\"üìù Saved journal:\\n  - {base.with_suffix('.md')}\\n  - {base.with_suffix('.json')}\")\n",
    "\n",
    "J = RunJournal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa5938d",
   "metadata": {},
   "source": [
    "# Cell 2 ‚Äî load data & PCA‚Üíangles (multi-dataset aware + logging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c18f109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ [load] Loaded encodings from encodings_all.npz and splits from splits_pooled.json\n",
      "‚úÖ [datasets] Detected 13 dataset(s) with mapping.\n",
      "‚úÖ [splits] train=12336, val=4112, test=4112, pos_rate=0.8654\n",
      "‚úÖ [pca] PCA to D=8 components (variance explained=0.614)\n",
      "‚úÖ [angles] Angle embedding created; clipped values ‚Äî train:345, val:148, test:144\n"
     ]
    }
   ],
   "source": [
    "# Try multi-dataset artifacts first; fall back to single-dataset artifacts\n",
    "enc_candidates = [PROCESSED/\"encodings_all.npz\", PROCESSED/\"encodings.npz\"]\n",
    "spl_candidates = [PROCESSED/\"splits_pooled.json\", PROCESSED/\"splits.json\"]\n",
    "\n",
    "enc_path = next((p for p in enc_candidates if p.exists()), None)\n",
    "spl_path = next((p for p in spl_candidates if p.exists()), None)\n",
    "\n",
    "if enc_path is None or spl_path is None:\n",
    "    if enc_path is None: J.log(\"load\", \"fail\", \"Encodings file not found (tried encodings_all.npz, encodings.npz)\")\n",
    "    if spl_path is None: J.log(\"load\", \"fail\", \"Splits file not found (tried splits_pooled.json, splits.json)\")\n",
    "    raise FileNotFoundError(\"Required data artifacts missing in data/processed\")\n",
    "\n",
    "data = np.load(enc_path, allow_pickle=True)\n",
    "with open(spl_path) as f:\n",
    "    SPL = json.load(f)\n",
    "J.log(\"load\", \"ok\", f\"Loaded encodings from {enc_path.name} and splits from {spl_path.name}\")\n",
    "\n",
    "y = data[\"y\"].astype(np.int64)\n",
    "X_kmer = data[\"kmer\"].astype(np.float32)\n",
    "\n",
    "# Optional per-dataset index\n",
    "ds_idx = data[\"ds_idx\"] if \"ds_idx\" in data.files else None\n",
    "ds_map = None\n",
    "ds_map_path = PROCESSED/\"dataset_index.csv\"\n",
    "if ds_idx is not None and ds_map_path.exists():\n",
    "    ds_map = pd.read_csv(ds_map_path).set_index(\"ds_idx\")[\"accession\"].to_dict()\n",
    "    J.log(\"datasets\", \"ok\", f\"Detected {len(set(ds_idx))} dataset(s) with mapping.\")\n",
    "elif ds_idx is not None:\n",
    "    J.log(\"datasets\", \"warn\", \"ds_idx present but dataset_index.csv missing ‚Äî names unavailable.\")\n",
    "\n",
    "tr_idx = np.array(SPL[\"train\"]); va_idx = np.array(SPL[\"val\"]); te_idx = np.array(SPL[\"test\"])\n",
    "pos_rate = float(y.mean()) if len(y) else float(\"nan\")\n",
    "J.log(\"splits\", \"ok\", f\"train={len(tr_idx)}, val={len(va_idx)}, test={len(te_idx)}, pos_rate={pos_rate:.4f}\")\n",
    "\n",
    "# PCA ‚Üí standardize ‚Üí angle map\n",
    "D = int(os.environ.get(\"QK_D\", \"8\"))  # number of principal components (== number of qubits)\n",
    "pca = PCA(n_components=D, random_state=7)\n",
    "X_tr_p = pca.fit_transform(X_kmer[tr_idx])\n",
    "X_va_p = pca.transform(X_kmer[va_idx])\n",
    "X_te_p = pca.transform(X_kmer[te_idx])\n",
    "\n",
    "ev = pca.explained_variance_ratio_.sum()\n",
    "J.log(\"pca\", \"ok\", f\"PCA to D={D} components (variance explained={ev:.3f})\")\n",
    "\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_tr_z = scaler.fit_transform(X_tr_p)\n",
    "X_va_z = scaler.transform(X_va_p)\n",
    "X_te_z = scaler.transform(X_te_p)\n",
    "\n",
    "# Angle map with clipping for robustness (document clipping rate)\n",
    "def to_angles(X, clip=3.0):\n",
    "    Xc = np.clip(X, -clip, clip)\n",
    "    return (np.pi * Xc / clip).astype(np.float32), float((np.abs(X) > clip).sum())\n",
    "\n",
    "Xtr, nclip_tr = to_angles(X_tr_z); Xva, nclip_va = to_angles(X_va_z); Xte, nclip_te = to_angles(X_te_z)\n",
    "J.log(\"angles\", \"ok\", f\"Angle embedding created; clipped values ‚Äî train:{int(nclip_tr)}, val:{int(nclip_va)}, test:{int(nclip_te)}\")\n",
    "\n",
    "# --- Fast knobs (can be overridden via env) ---\n",
    "MAX_TRAIN = int(os.environ.get(\"QK_MAX_TRAIN\", \"300\"))     # number of train rows used to build anchors\n",
    "N_ANCHORS = int(os.environ.get(\"QK_N_ANCHORS\", \"128\"))     # Nystr√∂m anchors (<= MAX_TRAIN)\n",
    "BATCH     = int(os.environ.get(\"QK_BATCH\", \"64\"))          # kernel batch size for vectorized eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024c8052",
   "metadata": {},
   "source": [
    "# Cell 3 ‚Äî device + kernel circuit (with device reporting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6746b1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ [device] Using lightning.qubit (wires=8, shots=None)\n"
     ]
    }
   ],
   "source": [
    "# Define embedding circuit and kernel evaluation (overlap) using an adjoint construction\n",
    "def make_device(n_wires, shots=None):\n",
    "    try:\n",
    "        dev_ = qml.device(\"lightning.qubit\", wires=n_wires, shots=shots)\n",
    "        J.log(\"device\", \"ok\", f\"Using lightning.qubit (wires={n_wires}, shots={shots})\")\n",
    "        return dev_\n",
    "    except Exception as e:\n",
    "        J.log(\"device\", \"warn\", f\"lightning.qubit unavailable ({e}); falling back to default.qubit\")\n",
    "        return qml.device(\"default.qubit\", wires=n_wires, shots=shots)\n",
    "\n",
    "n_wires = int(D)\n",
    "wires = list(range(n_wires))\n",
    "dev = make_device(n_wires, shots=None)\n",
    "\n",
    "def cz_ring(ws):\n",
    "    n = len(ws)\n",
    "    for i in range(n):\n",
    "        qml.CZ(wires=[ws[i], ws[(i+1) % n]])\n",
    "\n",
    "def U(x):\n",
    "    qml.AngleEmbedding(x, wires=wires, rotation=\"Y\")\n",
    "    cz_ring(wires)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def kernel_circuit(x1, x2):\n",
    "    U(x1)\n",
    "    qml.adjoint(U)(x2)\n",
    "    # Fidelity with |0...0> equals |<phi(x1)|phi(x2)>|^2\n",
    "    return qml.expval(qml.Projector([0]*n_wires, wires=wires))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d890be4d",
   "metadata": {},
   "source": [
    "# Cell 4 ‚Äî Gram matrices (symmetric speed-up + progress + saves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a261e557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ [device] Using lightning.qubit (wires=8, shots=None)\n",
      "‚ö†Ô∏è [kernel] Train truncated to 300 for speed.\n",
      "‚úÖ [kernel] Nystr√∂m anchors M=128 (from 300); batch=64\n",
      " rows 1-64/128 done\n",
      " rows 65-128/128 done\n",
      " rows 1-64/300 done\n",
      " rows 65-128/300 done\n",
      " rows 129-192/300 done\n",
      " rows 193-256/300 done\n",
      " rows 257-300/300 done\n",
      " rows 1-64/4112 done\n",
      " rows 65-128/4112 done\n",
      " rows 129-192/4112 done\n",
      " rows 193-256/4112 done\n",
      " rows 257-320/4112 done\n",
      " rows 321-384/4112 done\n",
      " rows 385-448/4112 done\n",
      " rows 449-512/4112 done\n",
      " rows 513-576/4112 done\n",
      " rows 577-640/4112 done\n",
      " rows 641-704/4112 done\n",
      " rows 705-768/4112 done\n",
      " rows 769-832/4112 done\n",
      " rows 833-896/4112 done\n",
      " rows 897-960/4112 done\n",
      " rows 961-1024/4112 done\n",
      " rows 1025-1088/4112 done\n",
      " rows 1089-1152/4112 done\n",
      " rows 1153-1216/4112 done\n",
      " rows 1217-1280/4112 done\n",
      " rows 1281-1344/4112 done\n",
      " rows 1345-1408/4112 done\n",
      " rows 1409-1472/4112 done\n",
      " rows 1473-1536/4112 done\n",
      " rows 1537-1600/4112 done\n",
      " rows 1601-1664/4112 done\n",
      " rows 1665-1728/4112 done\n",
      " rows 1729-1792/4112 done\n",
      " rows 1793-1856/4112 done\n",
      " rows 1857-1920/4112 done\n",
      " rows 1921-1984/4112 done\n",
      " rows 1985-2048/4112 done\n",
      " rows 2049-2112/4112 done\n",
      " rows 2113-2176/4112 done\n",
      " rows 2177-2240/4112 done\n",
      " rows 2241-2304/4112 done\n",
      " rows 2305-2368/4112 done\n",
      " rows 2369-2432/4112 done\n",
      " rows 2433-2496/4112 done\n",
      " rows 2497-2560/4112 done\n",
      " rows 2561-2624/4112 done\n",
      " rows 2625-2688/4112 done\n",
      " rows 2689-2752/4112 done\n",
      " rows 2753-2816/4112 done\n",
      " rows 2817-2880/4112 done\n",
      " rows 2881-2944/4112 done\n",
      " rows 2945-3008/4112 done\n",
      " rows 3009-3072/4112 done\n",
      " rows 3073-3136/4112 done\n",
      " rows 3137-3200/4112 done\n",
      " rows 3201-3264/4112 done\n",
      " rows 3265-3328/4112 done\n",
      " rows 3329-3392/4112 done\n",
      " rows 3393-3456/4112 done\n",
      " rows 3457-3520/4112 done\n",
      " rows 3521-3584/4112 done\n",
      " rows 3585-3648/4112 done\n",
      " rows 3649-3712/4112 done\n",
      " rows 3713-3776/4112 done\n",
      " rows 3777-3840/4112 done\n",
      " rows 3841-3904/4112 done\n",
      " rows 3905-3968/4112 done\n",
      " rows 3969-4032/4112 done\n",
      " rows 4033-4096/4112 done\n",
      " rows 4097-4112/4112 done\n",
      " rows 1-64/4112 done\n",
      " rows 65-128/4112 done\n",
      " rows 129-192/4112 done\n",
      " rows 193-256/4112 done\n",
      " rows 257-320/4112 done\n",
      " rows 321-384/4112 done\n",
      " rows 385-448/4112 done\n",
      " rows 449-512/4112 done\n",
      " rows 513-576/4112 done\n",
      " rows 577-640/4112 done\n",
      " rows 641-704/4112 done\n",
      " rows 705-768/4112 done\n",
      " rows 769-832/4112 done\n",
      " rows 833-896/4112 done\n",
      " rows 897-960/4112 done\n",
      " rows 961-1024/4112 done\n",
      " rows 1025-1088/4112 done\n",
      " rows 1089-1152/4112 done\n",
      " rows 1153-1216/4112 done\n",
      " rows 1217-1280/4112 done\n",
      " rows 1281-1344/4112 done\n",
      " rows 1345-1408/4112 done\n",
      " rows 1409-1472/4112 done\n",
      " rows 1473-1536/4112 done\n",
      " rows 1537-1600/4112 done\n",
      " rows 1601-1664/4112 done\n",
      " rows 1665-1728/4112 done\n",
      " rows 1729-1792/4112 done\n",
      " rows 1793-1856/4112 done\n",
      " rows 1857-1920/4112 done\n",
      " rows 1921-1984/4112 done\n",
      " rows 1985-2048/4112 done\n",
      " rows 2049-2112/4112 done\n",
      " rows 2113-2176/4112 done\n",
      " rows 2177-2240/4112 done\n",
      " rows 2241-2304/4112 done\n",
      " rows 2305-2368/4112 done\n",
      " rows 2369-2432/4112 done\n",
      " rows 2433-2496/4112 done\n",
      " rows 2497-2560/4112 done\n",
      " rows 2561-2624/4112 done\n",
      " rows 2625-2688/4112 done\n",
      " rows 2689-2752/4112 done\n",
      " rows 2753-2816/4112 done\n",
      " rows 2817-2880/4112 done\n",
      " rows 2881-2944/4112 done\n",
      " rows 2945-3008/4112 done\n",
      " rows 3009-3072/4112 done\n",
      " rows 3073-3136/4112 done\n",
      " rows 3137-3200/4112 done\n",
      " rows 3201-3264/4112 done\n",
      " rows 3265-3328/4112 done\n",
      " rows 3329-3392/4112 done\n",
      " rows 3393-3456/4112 done\n",
      " rows 3457-3520/4112 done\n",
      " rows 3521-3584/4112 done\n",
      " rows 3585-3648/4112 done\n",
      " rows 3649-3712/4112 done\n",
      " rows 3713-3776/4112 done\n",
      " rows 3777-3840/4112 done\n",
      " rows 3841-3904/4112 done\n",
      " rows 3905-3968/4112 done\n",
      " rows 3969-4032/4112 done\n",
      " rows 4033-4096/4112 done\n",
      " rows 4097-4112/4112 done\n",
      "‚úÖ [kernel] Computed Nystr√∂m blocks in 15018.1s\n",
      "saved Nystr√∂m blocks (K_MM, K_trM, K_vaM, K_teM, anchors_idx)\n"
     ]
    }
   ],
   "source": [
    "# Build fast Gram surrogates using Nystr√∂m anchors + batched kernel calls\n",
    "# Produces: K_trtr (M√óM), K_vatr (|val|√óM), K_tetr (|test|√óM) where M=N_ANCHORS\n",
    "\n",
    "def make_device(n_wires, shots=None):\n",
    "    try:\n",
    "        dev_ = qml.device(\"lightning.qubit\", wires=n_wires, shots=shots)\n",
    "        J.log(\"device\", \"ok\", f\"Using lightning.qubit (wires={n_wires}, shots={shots})\")\n",
    "        return dev_\n",
    "    except Exception as e:\n",
    "        J.log(\"device\", \"warn\", f\"lightning.qubit unavailable ({e}); falling back to default.qubit\")\n",
    "        return qml.device(\"default.qubit\", wires=n_wires, shots=shots)\n",
    "\n",
    "n_wires = int(D)\n",
    "wires = list(range(n_wires))\n",
    "dev = make_device(n_wires, shots=None)\n",
    "\n",
    "def cz_ring(ws):\n",
    "    n = len(ws)\n",
    "    for i in range(n):\n",
    "        qml.CZ(wires=[ws[i], ws[(i+1) % n]])\n",
    "\n",
    "def U(x):\n",
    "    qml.AngleEmbedding(x, wires=wires, rotation=\"Y\")\n",
    "    cz_ring(wires)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def kpair(x1, x2):\n",
    "    U(x1); qml.adjoint(U)(x2)\n",
    "    return qml.expval(qml.Projector([0]*n_wires, wires=wires))\n",
    "\n",
    "def kernel_block(XA, XB):\n",
    "    \"\"\"Compute |XA|√ó|XB| kernel in batches to reduce Python overhead.\"\"\"\n",
    "    m, n = len(XA), len(XB)\n",
    "    K = np.empty((m, n), dtype=np.float64)\n",
    "    for i0 in range(0, m, BATCH):\n",
    "        i1 = min(i0 + BATCH, m)\n",
    "        Xi = XA[i0:i1]\n",
    "        # vectorize over XB within Python loop (still qnode-per-pair but fewer Python frames)\n",
    "        for j in range(n):\n",
    "            xbj = XB[j]\n",
    "            for i, xi in enumerate(Xi):\n",
    "                K[i0 + i, j] = kpair(xi, xbj)\n",
    "        if (i1) % max(BATCH, 50) == 0 or i1 == m:\n",
    "            print(f\" rows {i0+1}-{i1}/{m} done\")\n",
    "    return K\n",
    "\n",
    "# 1) Subsample training for anchor candidates (MAX_TRAIN)\n",
    "sel_tr = tr_idx[: min(MAX_TRAIN, len(tr_idx))]\n",
    "Xtr_sub = Xtr[:len(sel_tr)]\n",
    "ytr_sub = y[sel_tr]\n",
    "if len(sel_tr) < len(tr_idx):\n",
    "    J.log(\"kernel\", \"warn\", f\"Train truncated to {len(sel_tr)} for speed.\")\n",
    "\n",
    "# 2) Choose Nystr√∂m anchors (uniform random or stratified)\n",
    "rng = np.random.default_rng(7)\n",
    "M = min(N_ANCHORS, len(Xtr_sub))\n",
    "anc_idx_local = rng.choice(len(Xtr_sub), size=M, replace=False)\n",
    "A = Xtr_sub[anc_idx_local]\n",
    "J.log(\"kernel\", \"ok\", f\"Nystr√∂m anchors M={M} (from {len(Xtr_sub)}); batch={BATCH}\")\n",
    "\n",
    "# 3) Compute anchor blocks only (fast)\n",
    "t0 = time.time()\n",
    "K_MM  = kernel_block(A, A)                 # M√óM\n",
    "K_trM = kernel_block(Xtr_sub, A)           # |tr_sub|√óM\n",
    "K_vaM = kernel_block(Xva, A)               # |val|√óM\n",
    "K_teM = kernel_block(Xte, A)               # |test|√óM\n",
    "J.log(\"kernel\", \"ok\", f\"Computed Nystr√∂m blocks in {time.time()-t0:.1f}s\")\n",
    "\n",
    "# 4) Save (to keep notebook outputs the same file names as before, save under kernels/)\n",
    "np.save(RESULTS/\"kernels/K_MM.npy\",  K_MM)\n",
    "np.save(RESULTS/\"kernels/K_trM.npy\", K_trM)\n",
    "np.save(RESULTS/\"kernels/K_vaM.npy\", K_vaM)\n",
    "np.save(RESULTS/\"kernels/K_teM.npy\", K_teM)\n",
    "np.save(RESULTS/\"kernels/anchors_idx.npy\", anc_idx_local)\n",
    "print(\"saved Nystr√∂m blocks (K_MM, K_trM, K_vaM, K_teM, anchors_idx)\")\n",
    "\n",
    "# 5) Report what we did / could not do\n",
    "if M < N_ANCHORS:\n",
    "    J.log(\"limit\", \"warn\", f\"Requested {N_ANCHORS} anchors but only {M} available.\")\n",
    "if M < 32:\n",
    "    J.log(\"limit\", \"warn\", \"Very small anchor set; metrics may be unstable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aa3186",
   "metadata": {},
   "source": [
    "# Cell 5 ‚Äî QSVM on precomputed kernel (full metrics, plots, docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8aed74a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ [fit] QSVM(Nystr√∂m): linear SVM on Œ¶_tr (shape=(300, 128)), C=5.0\n",
      "‚úÖ [threshold] val-optimal thr=0.50 (F1=0.923)\n",
      "acc                        0.865516\n",
      "prec                       0.866228\n",
      "rec                        0.998876\n",
      "f1                         0.927835\n",
      "roc_auc                    0.649885\n",
      "pr_auc                     0.907214\n",
      "specificity                0.007233\n",
      "balanced_acc               0.503055\n",
      "mcc                        0.047301\n",
      "thr                             0.5\n",
      "tp                             3555\n",
      "tn                                4\n",
      "fp                              549\n",
      "fn                                4\n",
      "support                        4112\n",
      "model           QSVM_kernel_nystrom\n",
      "split                          test\n",
      "M                               128\n",
      "‚úÖ [eval] QSVM(Nystr√∂m): metrics saved; see results/metrics and results/plots\n"
     ]
    }
   ],
   "source": [
    "# Train linear SVM on Nystr√∂m features  Œ¶ = K_{‚Ä¢M} K_MM^{-1/2}; produce same metrics/plots as before\n",
    "\n",
    "from numpy.linalg import eigh\n",
    "\n",
    "def nystrom_features(K_XM, K_MM, eps=1e-6):\n",
    "    # K_MM = V diag(w) V^T  ->  K_MM^{-1/2}\n",
    "    w, V = eigh(0.5*(K_MM + K_MM.T))\n",
    "    W = 1.0 / np.sqrt(np.clip(w, eps, None))\n",
    "    KMM_mhalf = V @ (np.diag(W)) @ V.T\n",
    "    return K_XM @ KMM_mhalf\n",
    "\n",
    "# Build feature maps\n",
    "Phi_tr = nystrom_features(K_trM, K_MM)\n",
    "Phi_va = nystrom_features(K_vaM, K_MM)\n",
    "Phi_te = nystrom_features(K_teM, K_MM)\n",
    "\n",
    "# Use the SAME labels as the rows used for K_trM (ytr_sub)\n",
    "C = float(os.environ.get(\"QK_C\", \"5.0\"))\n",
    "clf = SVC(C=C, kernel=\"linear\", probability=True, class_weight=\"balanced\", random_state=0)\n",
    "J.log(\"fit\", \"ok\", f\"QSVM(Nystr√∂m): linear SVM on Œ¶_tr (shape={Phi_tr.shape}), C={C}\")\n",
    "clf.fit(Phi_tr, ytr_sub)\n",
    "\n",
    "# Validation threshold\n",
    "from sklearn.metrics import f1_score\n",
    "p_val = clf.predict_proba(Phi_va)[:,1]\n",
    "thr_grid = np.linspace(0.05, 0.95, 37)\n",
    "best_thr, best_f1 = 0.5, -1\n",
    "for t in thr_grid:\n",
    "    f1 = f1_score(y[va_idx], (p_val >= t).astype(int), zero_division=0)\n",
    "    if f1 > best_f1:\n",
    "        best_f1, best_thr = float(f1), float(t)\n",
    "thr = best_thr\n",
    "J.log(\"threshold\", \"ok\", f\"val-optimal thr={thr:.2f} (F1={best_f1:.3f})\")\n",
    "\n",
    "def extended_metrics(y_true, y_prob, thr):\n",
    "    y_hat = (y_prob >= thr).astype(int)\n",
    "    acc = accuracy_score(y_true, y_hat)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_hat, average=\"binary\", zero_division=0)\n",
    "    try: auc = roc_auc_score(y_true, y_prob)\n",
    "    except: auc = float(\"nan\")\n",
    "    try: ap  = average_precision_score(y_true, y_prob)\n",
    "    except: ap  = float(\"nan\")\n",
    "    cm = confusion_matrix(y_true, y_hat, labels=[0,1])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    tnr = tn / (tn + fp) if (tn + fp) else float(\"nan\")\n",
    "    bal = balanced_accuracy_score(y_true, y_hat)\n",
    "    mcc = matthews_corrcoef(y_true, y_hat) if len(np.unique(y_true))==2 else float(\"nan\")\n",
    "    rep = classification_report(y_true, y_hat, output_dict=True, zero_division=0)\n",
    "    return {\n",
    "        \"acc\": acc, \"prec\": prec, \"rec\": rec, \"f1\": f1,\n",
    "        \"roc_auc\": auc, \"pr_auc\": ap, \"specificity\": tnr,\n",
    "        \"balanced_acc\": bal, \"mcc\": mcc, \"thr\": thr,\n",
    "        \"tp\": int(tp), \"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn),\n",
    "        \"support\": int(len(y_true)),\n",
    "    }, cm, rep\n",
    "\n",
    "# Evaluate splits\n",
    "rows, cms, reports = [], {}, {}\n",
    "for split, (Phi, y_true) in {\n",
    "    \"train\": (Phi_tr, ytr_sub),\n",
    "    \"val\":   (Phi_va,  y[va_idx]),\n",
    "    \"test\":  (Phi_te,  y[te_idx]),\n",
    "}.items():\n",
    "    p = clf.predict_proba(Phi)[:,1]\n",
    "    m, cm, rep = extended_metrics(y_true, p, thr)\n",
    "    m.update({\"model\":\"QSVM_kernel_nystrom\", \"split\":split, \"M\":int(Phi_tr.shape[1])})\n",
    "    rows.append(m); cms[split]=cm; reports[split]=rep\n",
    "\n",
    "df_metrics = pd.DataFrame(rows)\n",
    "df_metrics.to_csv(RESULTS/\"metrics/qsvm_kernel_metrics.csv\", index=False)\n",
    "\n",
    "# Confusion matrices (CSV)\n",
    "def save_cm_csv(cm, out_csv, normalized=False):\n",
    "    arr = cm.astype(np.float64)\n",
    "    if normalized:\n",
    "        rs = arr.sum(axis=1, keepdims=True)\n",
    "        arr = np.divide(arr, np.where(rs==0, 1, rs))\n",
    "    pd.DataFrame(arr, index=[\"true_0\",\"true_1\"], columns=[\"pred_0\",\"pred_1\"]).to_csv(out_csv, index=True)\n",
    "\n",
    "for split, cm in cms.items():\n",
    "    save_cm_csv(cm, RESULTS/f\"metrics/qsvm_kernel_cm_{split}.csv\", normalized=False)\n",
    "    save_cm_csv(cm, RESULTS/f\"metrics/qsvm_kernel_cm_{split}_norm.csv\", normalized=True)\n",
    "\n",
    "# ROC & PR for test\n",
    "def plot_roc(y_true, y_prob, title, out_png):\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(); plt.plot(fpr, tpr, label=f\"AUC={roc_auc:.3f}\")\n",
    "    plt.plot([0,1],[0,1],\"--\"); plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(title); plt.legend(); plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=150); plt.close()\n",
    "def plot_pr(y_true, y_prob, title, out_png):\n",
    "    from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "    prec, rec, _ = precision_recall_curve(y_true, y_prob)\n",
    "    ap = average_precision_score(y_true, y_prob)\n",
    "    plt.figure(); plt.plot(rec, prec, label=f\"AP={ap:.3f}\")\n",
    "    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(title); plt.legend(); plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=150); plt.close()\n",
    "\n",
    "p_test = clf.predict_proba(Phi_te)[:,1]\n",
    "plot_roc(y[te_idx], p_test, \"QSVM (Nystr√∂m) ‚Äî ROC (test)\", RESULTS/\"plots/qsvm_kernel_roc_test.png\")\n",
    "plot_pr (y[te_idx], p_test, \"QSVM (Nystr√∂m) ‚Äî PR  (test)\", RESULTS/\"plots/qsvm_kernel_pr_test.png\")\n",
    "\n",
    "print(df_metrics[df_metrics[\"split\"]==\"test\"].iloc[0].to_string())\n",
    "J.log(\"eval\", \"ok\", \"QSVM(Nystr√∂m): metrics saved; see results/metrics and results/plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fbaabe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ [kernel_cache] Saved approximate Gram matrices (train=(300, 300), val=(4112, 300), test=(4112, 300))\n"
     ]
    }
   ],
   "source": [
    "# Persist Gram matrices derived from Nystrom features for downstream notebooks\n",
    "K_trtr = Phi_tr @ Phi_tr.T\n",
    "K_vatr = Phi_va @ Phi_tr.T\n",
    "K_tetr = Phi_te @ Phi_tr.T\n",
    "\n",
    "kern_dir = RESULTS / \"kernels\"\n",
    "kern_dir.mkdir(parents=True, exist_ok=True)\n",
    "np.save(kern_dir / \"K_trtr.npy\", K_trtr.astype(np.float32))\n",
    "np.save(kern_dir / \"K_vatr.npy\", K_vatr.astype(np.float32))\n",
    "np.save(kern_dir / \"K_tetr.npy\", K_tetr.astype(np.float32))\n",
    "np.save(kern_dir / \"train_indices.npy\", sel_tr.astype(np.int64))\n",
    "np.save(kern_dir / \"val_indices.npy\", va_idx.astype(np.int64))\n",
    "np.save(kern_dir / \"test_indices.npy\", te_idx.astype(np.int64))\n",
    "J.log(\"kernel_cache\", \"ok\", f\"Saved approximate Gram matrices (train={K_trtr.shape}, val={K_vatr.shape}, test={K_tetr.shape})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd29f9e",
   "metadata": {},
   "source": [
    "# Cell 6 ‚Äî Save run journal (what worked, what didn‚Äôt, and why)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c3dede3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RUN SUMMARY ===\n",
      "Issues observed:\n",
      "- [kernel] Train truncated to 300 for speed.\n",
      "üìù Saved journal:\n",
      "  - results\\logs\\qsvm_kernel_20250918_201239.md\n",
      "  - results\\logs\\qsvm_kernel_20250918_201239.json\n",
      "üì¶ Metrics in: results\\metrics  |  Plots in: results\\plots  |  Kernels in: results\\kernels\n"
     ]
    }
   ],
   "source": [
    "ts = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "base = RESULTS/\"logs\"/f\"qsvm_kernel_{ts}\"\n",
    "\n",
    "issues = []\n",
    "for e in J.events:\n",
    "    if e[\"status\"] in (\"warn\",\"fail\"):\n",
    "        issues.append(f\"- [{e['step']}] {e['message']}\")\n",
    "rollup = \"No warnings or failures.\" if not issues else \"Issues observed:\\n\" + \"\\n\".join(issues)\n",
    "print(\"\\n=== RUN SUMMARY ===\\n\" + rollup)\n",
    "\n",
    "J.save(base)\n",
    "(RESULTS/\"logs\"/f\"qsvm_kernel_{ts}_summary.txt\").write_text(rollup, encoding=\"utf-8\")\n",
    "print(f\"üì¶ Metrics in: {RESULTS/'metrics'}  |  Plots in: {RESULTS/'plots'}  |  Kernels in: {RESULTS/'kernels'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
