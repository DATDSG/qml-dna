{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16568e51",
   "metadata": {},
   "source": [
    "# 03_quantum_kernel.ipynb â€” QSVM (precomputed kernel)\n",
    "\n",
    "This notebook computes a quantum kernel (via PennyLane) on PCAâ€‘reduced kâ€‘mer features and trains an SVM with the precomputed Gram matrix. Execute sequentially: Cell 0 (perf env) -> Cell 1 ... Cell 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0726471c",
   "metadata": {},
   "source": [
    "# Cell 0 â€” perf env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0b0ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize thread usage for reproducible classical linear algebra performance\n",
    "import os\n",
    "os.environ.setdefault(\"OMP_NUM_THREADS\", \"8\")\n",
    "os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"8\")\n",
    "os.environ.setdefault(\"MKL_NUM_THREADS\", \"8\")\n",
    "os.environ.setdefault(\"NUMEXPR_NUM_THREADS\", \"8\")\n",
    "print(\"BLAS threads:\", os.environ.get(\"OMP_NUM_THREADS\"), os.environ.get(\"OPENBLAS_NUM_THREADS\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05de0ea",
   "metadata": {},
   "source": [
    "# Cell 1 â€” imports, paths, journaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5606192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports: classical preprocessing + PennyLane for quantum kernel construction\n",
    "from pathlib import Path\n",
    "import json, warnings, time, os\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pennylane as qml\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix,\n",
    "    classification_report, balanced_accuracy_score, matthews_corrcoef, average_precision_score\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "ROOT = Path(\".\")\n",
    "PROCESSED = ROOT / \"data\" / \"processed\"\n",
    "RESULTS = ROOT / \"results\"\n",
    "(RESULTS / \"kernels\").mkdir(parents=True, exist_ok=True)\n",
    "(RESULTS / \"metrics\").mkdir(parents=True, exist_ok=True)\n",
    "(RESULTS / \"plots\").mkdir(parents=True, exist_ok=True)\n",
    "(RESULTS / \"logs\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.random.seed(7)\n",
    "\n",
    "# ---- Run journal (for documentation) ----\n",
    "class RunJournal:\n",
    "    def __init__(self): self.events = []\n",
    "    def log(self, step, status, message, **extras):\n",
    "        self.events.append({\n",
    "            \"ts\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"step\": step, \"status\": status, \"message\": message, **extras\n",
    "        })\n",
    "        sym = \"âœ…\" if status==\"ok\" else (\"âš ï¸\" if status==\"warn\" else \"âŒ\")\n",
    "        print(f\"{sym} [{step}] {message}\")\n",
    "    def df(self): return pd.DataFrame(self.events)\n",
    "    def save(self, base: Path):\n",
    "        df = self.df()\n",
    "        md = [\"| ts | step | status | message |\", \"|---|---|---|---|\"]\n",
    "        for _,r in df.iterrows():\n",
    "            md.append(f\"| {r.ts} | {r.step} | {r.status} | {r.message} |\")\n",
    "        (base.with_suffix(\".md\")).write_text(\"\\n\".join(md), encoding=\"utf-8\")\n",
    "        (base.with_suffix(\".json\")).write_text(df.to_json(orient=\"records\", indent=2), encoding=\"utf-8\")\n",
    "        print(f\"ðŸ“ Saved journal:\\n  - {base.with_suffix('.md')}\\n  - {base.with_suffix('.json')}\")\n",
    "\n",
    "J = RunJournal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa5938d",
   "metadata": {},
   "source": [
    "# Cell 2 â€” load data & PCAâ†’angles (multi-dataset aware + logging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c18f109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try multi-dataset artifacts first; fall back to single-dataset artifacts\n",
    "enc_candidates = [PROCESSED/\"encodings_all.npz\", PROCESSED/\"encodings.npz\"]\n",
    "spl_candidates = [PROCESSED/\"splits_pooled.json\", PROCESSED/\"splits.json\"]\n",
    "\n",
    "enc_path = next((p for p in enc_candidates if p.exists()), None)\n",
    "spl_path = next((p for p in spl_candidates if p.exists()), None)\n",
    "\n",
    "if enc_path is None or spl_path is None:\n",
    "    if enc_path is None: J.log(\"load\", \"fail\", \"Encodings file not found (tried encodings_all.npz, encodings.npz)\")\n",
    "    if spl_path is None: J.log(\"load\", \"fail\", \"Splits file not found (tried splits_pooled.json, splits.json)\")\n",
    "    raise FileNotFoundError(\"Required data artifacts missing in data/processed\")\n",
    "\n",
    "data = np.load(enc_path, allow_pickle=True)\n",
    "with open(spl_path) as f:\n",
    "    SPL = json.load(f)\n",
    "J.log(\"load\", \"ok\", f\"Loaded encodings from {enc_path.name} and splits from {spl_path.name}\")\n",
    "\n",
    "y = data[\"y\"].astype(np.int64)\n",
    "X_kmer = data[\"kmer\"].astype(np.float32)\n",
    "\n",
    "# Optional per-dataset index\n",
    "ds_idx = data[\"ds_idx\"] if \"ds_idx\" in data.files else None\n",
    "ds_map = None\n",
    "ds_map_path = PROCESSED/\"dataset_index.csv\"\n",
    "if ds_idx is not None and ds_map_path.exists():\n",
    "    ds_map = pd.read_csv(ds_map_path).set_index(\"ds_idx\")[\"accession\"].to_dict()\n",
    "    J.log(\"datasets\", \"ok\", f\"Detected {len(set(ds_idx))} dataset(s) with mapping.\")\n",
    "elif ds_idx is not None:\n",
    "    J.log(\"datasets\", \"warn\", \"ds_idx present but dataset_index.csv missing â€” names unavailable.\")\n",
    "\n",
    "tr_idx = np.array(SPL[\"train\"]); va_idx = np.array(SPL[\"val\"]); te_idx = np.array(SPL[\"test\"])\n",
    "pos_rate = float(y.mean()) if len(y) else float(\"nan\")\n",
    "J.log(\"splits\", \"ok\", f\"train={len(tr_idx)}, val={len(va_idx)}, test={len(te_idx)}, pos_rate={pos_rate:.4f}\")\n",
    "\n",
    "# PCA â†’ standardize â†’ angle map\n",
    "D = int(os.environ.get(\"QK_D\", \"8\"))  # number of principal components (== number of qubits)\n",
    "pca = PCA(n_components=D, random_state=7)\n",
    "X_tr_p = pca.fit_transform(X_kmer[tr_idx])\n",
    "X_va_p = pca.transform(X_kmer[va_idx])\n",
    "X_te_p = pca.transform(X_kmer[te_idx])\n",
    "\n",
    "ev = pca.explained_variance_ratio_.sum()\n",
    "J.log(\"pca\", \"ok\", f\"PCA to D={D} components (variance explained={ev:.3f})\")\n",
    "\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_tr_z = scaler.fit_transform(X_tr_p)\n",
    "X_va_z = scaler.transform(X_va_p)\n",
    "X_te_z = scaler.transform(X_te_p)\n",
    "\n",
    "# Angle map with clipping for robustness (document clipping rate)\n",
    "def to_angles(X, clip=3.0):\n",
    "    Xc = np.clip(X, -clip, clip)\n",
    "    return (np.pi * Xc / clip).astype(np.float32), float((np.abs(X) > clip).sum())\n",
    "\n",
    "Xtr, nclip_tr = to_angles(X_tr_z); Xva, nclip_va = to_angles(X_va_z); Xte, nclip_te = to_angles(X_te_z)\n",
    "J.log(\"angles\", \"ok\", f\"Angle embedding created; clipped values â€” train:{int(nclip_tr)}, val:{int(nclip_va)}, test:{int(nclip_te)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024c8052",
   "metadata": {},
   "source": [
    "# Cell 3 â€” device + kernel circuit (with device reporting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6746b1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define embedding circuit and kernel evaluation (overlap) using an adjoint construction\n",
    "def make_device(n_wires, shots=None):\n",
    "    try:\n",
    "        dev_ = qml.device(\"lightning.qubit\", wires=n_wires, shots=shots)\n",
    "        J.log(\"device\", \"ok\", f\"Using lightning.qubit (wires={n_wires}, shots={shots})\")\n",
    "        return dev_\n",
    "    except Exception as e:\n",
    "        J.log(\"device\", \"warn\", f\"lightning.qubit unavailable ({e}); falling back to default.qubit\")\n",
    "        return qml.device(\"default.qubit\", wires=n_wires, shots=shots)\n",
    "\n",
    "n_wires = int(D)\n",
    "wires = list(range(n_wires))\n",
    "dev = make_device(n_wires, shots=None)\n",
    "\n",
    "def cz_ring(ws):\n",
    "    n = len(ws)\n",
    "    for i in range(n):\n",
    "        qml.CZ(wires=[ws[i], ws[(i+1) % n]])\n",
    "\n",
    "def U(x):\n",
    "    qml.AngleEmbedding(x, wires=wires, rotation=\"Y\")\n",
    "    cz_ring(wires)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def kernel_circuit(x1, x2):\n",
    "    U(x1)\n",
    "    qml.adjoint(U)(x2)\n",
    "    # Fidelity with |0...0> equals |<phi(x1)|phi(x2)>|^2\n",
    "    return qml.expval(qml.Projector([0]*n_wires, wires=wires))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d890be4d",
   "metadata": {},
   "source": [
    "# Cell 4 â€” Gram matrices (symmetric speed-up + progress + saves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a261e557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Gram matrices (train-train, val-train, test-train) via pairwise quantum kernel evaluations\n",
    "\n",
    "def gram_matrix_square(X):\n",
    "    \"\"\"Symmetric Gram for XA vs XA (upper-triangular fill).\"\"\"\n",
    "    n = len(X)\n",
    "    K = np.zeros((n, n), dtype=np.float64)\n",
    "    for i in range(n):\n",
    "        K[i, i] = kernel_circuit(X[i], X[i])\n",
    "        for j in range(i+1, n):\n",
    "            kij = kernel_circuit(X[i], X[j])\n",
    "            K[i, j] = kij\n",
    "            K[j, i] = kij\n",
    "        if (i+1) % 50 == 0 or i == n-1:\n",
    "            print(f\" row {i+1}/{n} ready\")\n",
    "    return K\n",
    "\n",
    "def gram_matrix_rect(XA, XB):\n",
    "    \"\"\"Rectangular Gram for XA vs XB.\"\"\"\n",
    "    K = np.zeros((len(XA), len(XB)), dtype=np.float64)\n",
    "    for i in range(len(XA)):\n",
    "        for j in range(len(XB)):\n",
    "            K[i, j] = kernel_circuit(XA[i], XB[j])\n",
    "        if (i+1) % 50 == 0 or i == len(XA)-1:\n",
    "            print(f\" row {i+1}/{len(XA)} ready\")\n",
    "    return K\n",
    "\n",
    "# Control kernel cost via truncation\n",
    "MAX_TRAIN = int(os.environ.get(\"QK_MAX_TRAIN\", \"600\"))  # set small (e.g., 600) if too slow\n",
    "sel_tr = tr_idx[: (MAX_TRAIN or len(tr_idx))]\n",
    "Xtr_sel, ytr_sel = Xtr[:len(sel_tr)], y[sel_tr]\n",
    "if len(sel_tr) < len(tr_idx):\n",
    "    J.log(\"kernel\", \"warn\", f\"Training truncated to first {len(sel_tr)} samples for kernel cost control.\")\n",
    "\n",
    "t0 = time.time()\n",
    "K_trtr = gram_matrix_square(Xtr_sel)\n",
    "K_vatr = gram_matrix_rect(Xva, Xtr_sel)\n",
    "K_tetr = gram_matrix_rect(Xte, Xtr_sel)\n",
    "dt = time.time() - t0\n",
    "J.log(\"kernel\", \"ok\", f\"Computed Gram matrices in {dt/60:.1f} min (train={K_trtr.shape}, val={K_vatr.shape}, test={K_tetr.shape})\")\n",
    "\n",
    "np.save(RESULTS/\"kernels/K_trtr.npy\", K_trtr)\n",
    "np.save(RESULTS/\"kernels/K_vatr.npy\", K_vatr)\n",
    "np.save(RESULTS/\"kernels/K_tetr.npy\", K_tetr)\n",
    "print(\"saved gram matrices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aa3186",
   "metadata": {},
   "source": [
    "# Cell 5 â€” QSVM on precomputed kernel (full metrics, plots, docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aed74a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVM with precomputed quantum kernel; full metrics & plots\n",
    "\n",
    "def choose_threshold(y_val, p_val, name=\"QSVM\"):\n",
    "    grid = np.linspace(0.05, 0.95, 37)\n",
    "    best_thr, best_f1 = 0.5, -1\n",
    "    from sklearn.metrics import f1_score\n",
    "    for t in grid:\n",
    "        f1 = f1_score(y_val, (p_val >= t).astype(int), zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_thr = float(f1), float(t)\n",
    "    if np.isnan(best_f1):\n",
    "        J.log(\"threshold\", \"warn\", f\"{name}: F1 undefined on val; using default thr=0.5\")\n",
    "        return 0.5\n",
    "    J.log(\"threshold\", \"ok\", f\"{name}: selected thr={best_thr:.2f} (val F1={best_f1:.3f})\")\n",
    "    return best_thr\n",
    "\n",
    "def extended_metrics(y_true, y_prob, thr):\n",
    "    y_hat = (y_prob >= thr).astype(int)\n",
    "    acc = accuracy_score(y_true, y_hat)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_hat, average=\"binary\", zero_division=0)\n",
    "    try: auc = roc_auc_score(y_true, y_prob)\n",
    "    except Exception: auc = float(\"nan\")\n",
    "    try: ap  = average_precision_score(y_true, y_prob)\n",
    "    except Exception: ap  = float(\"nan\")\n",
    "    cm = confusion_matrix(y_true, y_hat, labels=[0,1])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    tnr = tn / (tn + fp) if (tn + fp) else float(\"nan\")  # specificity\n",
    "    bal = balanced_accuracy_score(y_true, y_hat)\n",
    "    mcc = matthews_corrcoef(y_true, y_hat) if len(np.unique(y_true))==2 else float(\"nan\")\n",
    "    rep = classification_report(y_true, y_hat, output_dict=True, zero_division=0)\n",
    "    return {\n",
    "        \"acc\": acc, \"prec\": prec, \"rec\": rec, \"f1\": f1,\n",
    "        \"roc_auc\": auc, \"pr_auc\": ap, \"specificity\": tnr,\n",
    "        \"balanced_acc\": bal, \"mcc\": mcc, \"thr\": thr,\n",
    "        \"tp\": int(tp), \"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn),\n",
    "        \"support\": int(len(y_true)),\n",
    "    }, cm, rep\n",
    "\n",
    "def save_cm_csv(cm, out_csv, normalized=False):\n",
    "    if normalized:\n",
    "        cm = cm.astype(np.float64)\n",
    "        rs = cm.sum(axis=1, keepdims=True)\n",
    "        cm = np.divide(cm, np.where(rs==0, 1, rs))\n",
    "    df = pd.DataFrame(cm, index=[\"true_0\",\"true_1\"], columns=[\"pred_0\",\"pred_1\"])\n",
    "    df.to_csv(out_csv, index=True)\n",
    "\n",
    "def plot_roc(y_true, y_prob, title, out_png):\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    try:\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.figure(); plt.plot(fpr, tpr, label=f\"AUC={roc_auc:.3f}\")\n",
    "        plt.plot([0,1],[0,1], linestyle=\"--\")\n",
    "        plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(title); plt.legend(loc=\"lower right\"); plt.tight_layout()\n",
    "        plt.savefig(out_png, dpi=150); plt.close()\n",
    "    except Exception as e:\n",
    "        J.log(\"plot\", \"warn\", f\"ROC plot skipped: {e}\")\n",
    "\n",
    "def plot_pr(y_true, y_prob, title, out_png):\n",
    "    from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "    try:\n",
    "        prec, rec, _ = precision_recall_curve(y_true, y_prob)\n",
    "        ap = average_precision_score(y_true, y_prob)\n",
    "        plt.figure(); plt.plot(rec, prec, label=f\"AP={ap:.3f}\")\n",
    "        plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(title); plt.legend(loc=\"lower left\"); plt.tight_layout()\n",
    "        plt.savefig(out_png, dpi=150); plt.close()\n",
    "    except Exception as e:\n",
    "        J.log(\"plot\", \"warn\", f\"PR plot skipped: {e}\")\n",
    "\n",
    "# --- Train QSVM (precomputed kernel) ---\n",
    "C = float(os.environ.get(\"QK_C\", \"5.0\"))\n",
    "clf = SVC(C=C, kernel=\"precomputed\", probability=True, class_weight=\"balanced\", random_state=0)\n",
    "J.log(\"fit\", \"ok\", f\"QSVM: fitting on K_trtr (shape={K_trtr.shape}, C={C})\")\n",
    "clf.fit(K_trtr, ytr_sel)\n",
    "\n",
    "# Choose threshold on validation (using K_vatr)\n",
    "p_val = clf.predict_proba(K_vatr)[:,1]\n",
    "thr = choose_threshold(y[va_idx], p_val, name=\"QSVM\")\n",
    "\n",
    "# Evaluate splits\n",
    "splits = {\n",
    "    \"train\": (K_trtr, ytr_sel),\n",
    "    \"val\":   (K_vatr,  y[va_idx]),\n",
    "    \"test\":  (K_tetr,  y[te_idx]),\n",
    "}\n",
    "\n",
    "rows, reports, cms = [], {}, {}\n",
    "for split,(K,y_true) in splits.items():\n",
    "    p = clf.predict_proba(K)[:,1]\n",
    "    m, cm, rep = extended_metrics(y_true, p, thr)\n",
    "    m.update({\"model\":\"QSVM_kernel\", \"split\":split})\n",
    "    rows.append(m); cms[split]=cm; reports[split]=rep\n",
    "\n",
    "# Save metrics\n",
    "\n",
    "df_metrics = pd.DataFrame(rows)\n",
    "df_metrics.to_csv(RESULTS/\"metrics/qsvm_kernel_metrics.csv\", index=False)\n",
    "\n",
    "for split, cm in cms.items():\n",
    "    save_cm_csv(cm, RESULTS/f\"metrics/qsvm_kernel_cm_{split}.csv\", normalized=False)\n",
    "    save_cm_csv(cm, RESULTS/f\"metrics/qsvm_kernel_cm_{split}_norm.csv\", normalized=True)\n",
    "\n",
    "with open(RESULTS/\"metrics/qsvm_kernel_classification_reports.json\",\"w\",encoding=\"utf-8\") as f:\n",
    "    json.dump(reports, f, indent=2)\n",
    "\n",
    "# Plots (test)\n",
    "plot_roc(y[te_idx], clf.predict_proba(K_tetr)[:,1], \"QSVM â€” ROC (test)\", RESULTS/\"plots/qsvm_kernel_roc_test.png\")\n",
    "plot_pr (y[te_idx], clf.predict_proba(K_tetr)[:,1], \"QSVM â€” PR (test)\",  RESULTS/\"plots/qsvm_kernel_pr_test.png\")\n",
    "\n",
    "# Console + journal summary\n",
    "row_test = df_metrics.loc[df_metrics[\"split\"]==\"test\"].iloc[0]\n",
    "print(row_test.to_string())\n",
    "\n",
    "J.log(\n",
    "    \"eval\", \"ok\",\n",
    "    f\"QSVM: test F1={row_test['f1']:.3f}, AUC={row_test['roc_auc']:.3f}, PR-AUC={row_test['pr_auc']:.3f}, thr={thr:.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5f44a6",
   "metadata": {},
   "source": [
    "# (Optional) Cell 6 â€” Per-dataset test diagnostics (if ds_idx available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03167254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate generalization per dataset on TEST split only (reuse global thr)\n",
    "if ds_idx is None:\n",
    "    J.log(\"per-dataset\", \"warn\", \"ds_idx not found â€” skipping per-dataset diagnostics.\")\n",
    "else:\n",
    "    rows = []\n",
    "    uniq = sorted(np.unique(ds_idx[te_idx]))\n",
    "    for d in uniq:\n",
    "        name = ds_map.get(d, f\"ds_{d}\") if ds_map else f\"ds_{d}\"\n",
    "        mask = (ds_idx[te_idx] == d)\n",
    "        if mask.sum() == 0: \n",
    "            continue\n",
    "        y_true = y[te_idx][mask]\n",
    "        K_sub  = K_tetr[mask, :]  # rows subset; columns stay as train\n",
    "        y_prob = clf.predict_proba(K_sub)[:,1]\n",
    "        m, cm, _ = extended_metrics(y_true, y_prob, thr)\n",
    "        m.update({\"model\":\"QSVM_kernel\", \"dataset\":name, \"n\": int(mask.sum())})\n",
    "        rows.append(m)\n",
    "    df_per = pd.DataFrame(rows)\n",
    "    df_per.to_csv(RESULTS/\"metrics/qsvm_kernel_per_dataset_test.csv\", index=False)\n",
    "    J.log(\"per-dataset\", \"ok\", f\"Saved per-dataset test metrics for {len(df_per)} dataset(s).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd29f9e",
   "metadata": {},
   "source": [
    "# (Final) Cell 7 â€” Save run journal (what worked, what didnâ€™t, and why)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3dede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "base = RESULTS/\"logs\"/f\"qsvm_kernel_{ts}\"\n",
    "\n",
    "issues = []\n",
    "for e in J.events:\n",
    "    if e[\"status\"] in (\"warn\",\"fail\"):\n",
    "        issues.append(f\"- [{e['step']}] {e['message']}\")\n",
    "rollup = \"No warnings or failures.\" if not issues else \"Issues observed:\\n\" + \"\\n\".join(issues)\n",
    "print(\"\\n=== RUN SUMMARY ===\\n\" + rollup)\n",
    "\n",
    "J.save(base)\n",
    "(RESULTS/\"logs\"/f\"qsvm_kernel_{ts}_summary.txt\").write_text(rollup, encoding=\"utf-8\")\n",
    "print(f\"ðŸ“¦ Metrics in: {RESULTS/'metrics'}  |  Plots in: {RESULTS/'plots'}  |  Kernels in: {RESULTS/'kernels'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
