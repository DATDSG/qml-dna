{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54765e22",
   "metadata": {},
   "source": [
    "# 04_quantum_vqc.ipynb — Variational Quantum Classifier (shallow, re-uploading)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167517fb",
   "metadata": {},
   "source": [
    "# Cell 0 — perf env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed3c093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize underlying BLAS thread counts for reproducible timing\n",
    "import os\n",
    "os.environ.setdefault(\"OMP_NUM_THREADS\", \"8\")\n",
    "os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"8\")\n",
    "os.environ.setdefault(\"MKL_NUM_THREADS\", \"8\")\n",
    "os.environ.setdefault(\"NUMEXPR_NUM_THREADS\", \"8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f321e39",
   "metadata": {},
   "source": [
    "# Cell 1 — imports & data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8f5ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((894, 6), np.float64(0.9228187919463087))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load k-mer encodings; reduce dimension with PCA; scale features; prepare train/val/test splits\n",
    "from pathlib import Path\n",
    "import json, warnings, numpy as np, pandas as pd\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ROOT = Path(\".\"); PROCESSED = ROOT/\"data/processed\"; RESULTS = ROOT/\"results\"\n",
    "(RESULTS/\"metrics\").mkdir(parents=True, exist_ok=True)\n",
    "np.random.seed(11); pnp.random.seed(11)\n",
    "\n",
    "data = np.load(PROCESSED/\"encodings.npz\", allow_pickle=True)\n",
    "with open(PROCESSED/\"splits.json\") as f: SPL = json.load(f)\n",
    "y = data[\"y\"]; X_kmer = data[\"kmer\"].astype(np.float32)\n",
    "tr_idx = np.array(SPL[\"train\"]); va_idx = np.array(SPL[\"val\"]); te_idx = np.array(SPL[\"test\"])\n",
    "\n",
    "D = 6\n",
    "pca = PCA(n_components=D, random_state=11)\n",
    "X_tr = pca.fit_transform(X_kmer[tr_idx])\n",
    "X_va = pca.transform(X_kmer[va_idx])\n",
    "X_te = pca.transform(X_kmer[te_idx])\n",
    "\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "Xtr = scaler.fit_transform(X_tr).astype(np.float32)\n",
    "Xva = scaler.transform(X_va).astype(np.float32)\n",
    "Xte = scaler.transform(X_te).astype(np.float32)\n",
    "ytr, yva, yte = y[tr_idx].astype(int), y[va_idx].astype(int), y[te_idx].astype(int)\n",
    "Xtr.shape, ytr.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eac12aa",
   "metadata": {},
   "source": [
    "# Cell 2 — device + circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4537de86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define shallow variational circuit (re-uploading style) and helper prediction routine\n",
    "def make_device(n_wires, shots=None, use_mixed=False):\n",
    "    backend = \"default.mixed\" if use_mixed else \"lightning.qubit\"\n",
    "    try:\n",
    "        return qml.device(backend, wires=n_wires, shots=shots)\n",
    "    except Exception:\n",
    "        return qml.device(\"default.qubit\", wires=n_wires, shots=shots)\n",
    "\n",
    "n_wires = D; L = 2\n",
    "dev = make_device(n_wires, shots=None, use_mixed=False)\n",
    "\n",
    "# Robust import for entangler layer across PennyLane versions\n",
    "try:\n",
    "    BasicEntanglerLayers = qml.BasicEntanglerLayers\n",
    "except AttributeError:\n",
    "    from pennylane.templates.layers import BasicEntanglerLayers\n",
    "\n",
    "weights = pnp.random.normal(scale=0.15, size=(L, n_wires), requires_grad=True)\n",
    "\n",
    "def layer(x, w, p_bitflip=0.0, p_depol=0.0):\n",
    "    qml.AngleEmbedding(x, wires=range(n_wires), rotation=\"Y\")\n",
    "    if p_bitflip>0:\n",
    "        for i in range(n_wires):\n",
    "            qml.BitFlip(p_bitflip, wires=i)\n",
    "    if p_depol>0:\n",
    "        for i in range(n_wires):\n",
    "            qml.DepolarizingChannel(p_depol, wires=i)\n",
    "    BasicEntanglerLayers(w[None, :], wires=range(n_wires))\n",
    "\n",
    "@qml.qnode(dev, interface=\"autograd\")\n",
    "def vqc(x, w):\n",
    "    for l in range(L):\n",
    "        layer(x, w[l])\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "def predict_proba(X, w, as_numpy=False):\n",
    "    vals = []\n",
    "    for xi in X:\n",
    "        m = vqc(xi, w)           # Possibly an autograd ArrayBox\n",
    "        vals.append((1 + m)/2)   # Map expectation [-1,1] -> probability [0,1]\n",
    "    p = pnp.clip(pnp.stack(vals), 1e-6, 1-1e-6)\n",
    "    if as_numpy:  # Explicit conversion after gradient use\n",
    "        return np.asarray(p)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583200a5",
   "metadata": {},
   "source": [
    "# Cell 3 — train (Adam + early stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257728fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01 | loss_tr=0.6535 | loss_va=0.6475\n",
      "epoch 02 | loss_tr=0.6472 | loss_va=0.6375\n",
      "epoch 03 | loss_tr=0.6284 | loss_va=0.6157\n",
      "epoch 04 | loss_tr=0.5795 | loss_va=0.5643\n",
      "epoch 05 | loss_tr=0.5471 | loss_va=0.5406\n",
      "epoch 06 | loss_tr=0.5471 | loss_va=0.5418\n",
      "epoch 07 | loss_tr=0.5461 | loss_va=0.5398\n",
      "epoch 08 | loss_tr=0.5454 | loss_va=0.5399\n",
      "epoch 09 | loss_tr=0.5452 | loss_va=0.5407\n",
      "epoch 10 | loss_tr=0.5449 | loss_va=0.5400\n",
      "epoch 11 | loss_tr=0.5447 | loss_va=0.5403\n",
      "epoch 12 | loss_tr=0.5448 | loss_va=0.5407\n",
      "epoch 13 | loss_tr=0.5448 | loss_va=0.5406\n",
      "early stopping.\n"
     ]
    }
   ],
   "source": [
    "# Optimize VQC parameters with mini-batch stochastic Adam + early stopping on validation loss\n",
    "opt = qml.AdamOptimizer(stepsize=0.05)\n",
    "batch_size = 64; max_epochs = 60; patience = 6\n",
    "best_va = float(\"inf\"); best_w = pnp.array(weights, requires_grad=True); no_improve = 0\n",
    "history = []\n",
    "\n",
    "def bce_loss(y_true, p_hat):\n",
    "    return -pnp.mean(y_true*pnp.log(p_hat) + (1-y_true)*pnp.log(1-p_hat))\n",
    "\n",
    "def iterate_minibatches(X, y, bs, shuffle=True):\n",
    "    idx = np.arange(len(y))\n",
    "    if shuffle:\n",
    "        np.random.shuffle(idx)\n",
    "    for i in range(0, len(y), bs):\n",
    "        sl = idx[i:i+bs]\n",
    "        yield X[sl], y[sl]\n",
    "\n",
    "for epoch in range(1, max_epochs+1):\n",
    "    for Xb, yb in iterate_minibatches(Xtr, ytr, batch_size):\n",
    "        def cost(w):\n",
    "            y_true = pnp.array(yb, dtype=float)\n",
    "            p_hat  = predict_proba(Xb, w, as_numpy=False)\n",
    "            return bce_loss(y_true, p_hat)\n",
    "\n",
    "        w_new = opt.step(cost, weights)\n",
    "        weights = pnp.clip(w_new, -1.5, 1.5)  # Simple parameter clipping to stabilize training\n",
    "\n",
    "    p_tr = predict_proba(Xtr, weights); p_va = predict_proba(Xva, weights)\n",
    "    loss_tr = float(bce_loss(ytr, p_tr)); loss_va = float(bce_loss(yva, p_va))\n",
    "    history.append({\"epoch\":epoch, \"loss_tr\":loss_tr, \"loss_va\":loss_va})\n",
    "    print(f\"epoch {epoch:02d} | loss_tr={loss_tr:.4f} | loss_va={loss_va:.4f}\")\n",
    "\n",
    "    if loss_va + 1e-4 < best_va:\n",
    "        best_va = float(loss_va); best_w = pnp.array(weights, requires_grad=False); no_improve = 0\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= patience:\n",
    "            print(\"early stopping.\"); break\n",
    "\n",
    "weights = best_w\n",
    "pd.DataFrame(history).to_csv(RESULTS/\"metrics/vqc_train_curve.csv\", index=False)\n",
    "np.save(RESULTS/\"vqc_weights.npy\", np.array(weights, dtype=float))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc6a61a",
   "metadata": {},
   "source": [
    "# Cell 4 — metrics (val-optimal threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4511792f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'model': 'VQC',\n",
       "  'split': 'test',\n",
       "  'acc': 0.9228187919463087,\n",
       "  'prec': 0.9228187919463087,\n",
       "  'rec': 1.0,\n",
       "  'f1': 0.9598603839441536,\n",
       "  'auc': 0.5109881422924901,\n",
       "  'thr': 0.1},\n",
       " array([[  0,  23],\n",
       "        [  0, 275]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine decision threshold maximizing validation F1; report metrics for all splits\n",
    "from sklearn.metrics import f1_score\n",
    "thr_grid = np.linspace(0.1,0.9,33)\n",
    "p_tr = predict_proba(Xtr, weights, as_numpy=True)\n",
    "p_va = predict_proba(Xva, weights, as_numpy=True)\n",
    "p_te = predict_proba(Xte, weights, as_numpy=True)\n",
    "best_thr, best_f1 = 0.5, -1.0\n",
    "for t in thr_grid:\n",
    "    f1 = f1_score(yva, (p_va>=t).astype(int), zero_division=0)\n",
    "    if f1>best_f1:\n",
    "        best_thr, best_f1 = float(t), float(f1)\n",
    "\n",
    "def pack(y_true, p, split):\n",
    "    yhat = (p>=best_thr).astype(int)\n",
    "    acc = accuracy_score(y_true, yhat)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, yhat, average=\"binary\", zero_division=0)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, p)\n",
    "    except Exception:\n",
    "        auc = float(\"nan\")\n",
    "    cm = confusion_matrix(y_true, yhat)\n",
    "    return dict(model=\"VQC\", split=split, acc=acc, prec=prec, rec=rec, f1=f1, auc=auc, thr=best_thr), cm\n",
    "\n",
    "m_tr, _ = pack(ytr, p_tr, \"train\")\n",
    "m_va, _ = pack(yva, p_va, \"val\")\n",
    "m_te, cm_te = pack(yte, p_te, \"test\")\n",
    "pd.DataFrame([m_tr,m_va,m_te]).to_csv(RESULTS/\"metrics/vqc.csv\", index=False)\n",
    "m_te, cm_te"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
