{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9c1ff44",
   "metadata": {},
   "source": [
    "# 04_quantum_vqc.ipynb ‚Äî Variational Quantum Classifier (shallow, re-uploading)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167517fb",
   "metadata": {},
   "source": [
    "# Cell 0 ‚Äî perf env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4990de46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize underlying BLAS thread counts for reproducible timing\n",
    "import os\n",
    "os.environ.setdefault(\"OMP_NUM_THREADS\", \"8\")\n",
    "os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"8\")\n",
    "os.environ.setdefault(\"MKL_NUM_THREADS\", \"8\")\n",
    "os.environ.setdefault(\"NUMEXPR_NUM_THREADS\", \"8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcce2c9",
   "metadata": {},
   "source": [
    "# Cell 1 ‚Äî imports & data (multi-dataset + journaling + PCA/scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea82d09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ [load] Loaded encodings from encodings_all.npz and splits from splits_pooled.json\n",
      "‚úÖ [datasets] Detected 13 dataset(s) with mapping.\n",
      "‚úÖ [splits] train=12336, val=4112, test=4112, pos_rate=0.8654\n",
      "‚úÖ [pca] PCA D=6, explained_var=0.563\n",
      "(12336, 6) 0.8654345006485085\n"
     ]
    }
   ],
   "source": [
    "# Load k-mer encodings; reduce dimension with PCA; scale; prepare splits (multi-dataset aware)\n",
    "from pathlib import Path\n",
    "import json, warnings, time, os\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix,\n",
    "    balanced_accuracy_score, matthews_corrcoef, classification_report, average_precision_score\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ROOT = Path(\".\"); PROCESSED = ROOT/\"data/processed\"; RESULTS = ROOT/\"results\"\n",
    "(RESULTS/\"metrics\").mkdir(parents=True, exist_ok=True)\n",
    "(RESULTS/\"plots\").mkdir(parents=True, exist_ok=True)\n",
    "(RESULTS/\"logs\").mkdir(parents=True, exist_ok=True)\n",
    "np.random.seed(11); pnp.random.seed(11)\n",
    "\n",
    "# ---- Run journal (for documentation) ----\n",
    "class RunJournal:\n",
    "    def __init__(self): self.events=[]\n",
    "    def log(self, step, status, message, **extras):\n",
    "        self.events.append({\"ts\":time.strftime(\"%Y-%m-%d %H:%M:%S\"),\"step\":step,\"status\":status,\"message\":message,**extras})\n",
    "        sym = \"‚úÖ\" if status==\"ok\" else (\"‚ö†Ô∏è\" if status==\"warn\" else \"‚ùå\")\n",
    "        print(f\"{sym} [{step}] {message}\")\n",
    "    def df(self): return pd.DataFrame(self.events)\n",
    "    def save(self, base):\n",
    "        df = self.df()\n",
    "        md = [\"| ts | step | status | message |\",\"|---|---|---|---|\"]\n",
    "        for _,r in df.iterrows(): md.append(f\"| {r.ts} | {r.step} | {r.status} | {r.message} |\")\n",
    "        (base.with_suffix(\".md\")).write_text(\"\\n\".join(md), encoding=\"utf-8\")\n",
    "        (base.with_suffix(\".json\")).write_text(df.to_json(orient=\"records\", indent=2), encoding=\"utf-8\")\n",
    "        print(f\"üìù Saved journal:\\n  - {base.with_suffix('.md')}\\n  - {base.with_suffix('.json')}\")\n",
    "J = RunJournal()\n",
    "\n",
    "# Prefer multi-dataset artifacts; fall back to original\n",
    "enc_candidates = [PROCESSED/\"encodings_all.npz\", PROCESSED/\"encodings.npz\"]\n",
    "spl_candidates = [PROCESSED/\"splits_pooled.json\", PROCESSED/\"splits.json\"]\n",
    "enc_path = next((p for p in enc_candidates if p.exists()), None)\n",
    "spl_path = next((p for p in spl_candidates if p.exists()), None)\n",
    "if enc_path is None or spl_path is None:\n",
    "    if enc_path is None: J.log(\"load\",\"fail\",\"Encodings not found (tried encodings_all.npz, encodings.npz)\")\n",
    "    if spl_path is None: J.log(\"load\",\"fail\",\"Splits not found (tried splits_pooled.json, splits.json)\")\n",
    "    raise FileNotFoundError(\"Missing required artifacts in data/processed\")\n",
    "data = np.load(enc_path, allow_pickle=True)\n",
    "with open(spl_path) as f: SPL = json.load(f)\n",
    "J.log(\"load\",\"ok\",f\"Loaded encodings from {enc_path.name} and splits from {spl_path.name}\")\n",
    "\n",
    "y = data[\"y\"].astype(int)\n",
    "X_kmer = data[\"kmer\"].astype(np.float32)\n",
    "\n",
    "# Optional dataset index for per-dataset diagnostics\n",
    "ds_idx = data[\"ds_idx\"] if \"ds_idx\" in data.files else None\n",
    "ds_map = None\n",
    "if ds_idx is not None and (PROCESSED/\"dataset_index.csv\").exists():\n",
    "    ds_map = pd.read_csv(PROCESSED/\"dataset_index.csv\").set_index(\"ds_idx\")[\"accession\"].to_dict()\n",
    "    J.log(\"datasets\",\"ok\",f\"Detected {len(set(ds_idx))} dataset(s) with mapping.\")\n",
    "\n",
    "tr_idx = np.array(SPL[\"train\"]); va_idx = np.array(SPL[\"val\"]); te_idx = np.array(SPL[\"test\"])\n",
    "J.log(\"splits\",\"ok\",f\"train={len(tr_idx)}, val={len(va_idx)}, test={len(te_idx)}, pos_rate={y.mean():.4f}\")\n",
    "\n",
    "# PCA ‚Üí scale\n",
    "D = int(os.environ.get(\"VQC_D\",\"6\"))\n",
    "pca = PCA(n_components=D, random_state=11)\n",
    "X_tr = pca.fit_transform(X_kmer[tr_idx])\n",
    "X_va = pca.transform(X_kmer[va_idx])\n",
    "X_te = pca.transform(X_kmer[te_idx])\n",
    "J.log(\"pca\",\"ok\",f\"PCA D={D}, explained_var={pca.explained_variance_ratio_.sum():.3f}\")\n",
    "\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "Xtr = scaler.fit_transform(X_tr).astype(np.float32)\n",
    "Xva = scaler.transform(X_va).astype(np.float32)\n",
    "Xte = scaler.transform(X_te).astype(np.float32)\n",
    "ytr, yva, yte = y[tr_idx], y[va_idx], y[te_idx]\n",
    "print(Xtr.shape, ytr.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5966bc00",
   "metadata": {},
   "source": [
    "# Cell 2 ‚Äî device + circuit (robust, optional noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe0a889c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ [device] lightning.qubit (wires=6, shots=None)\n"
     ]
    }
   ],
   "source": [
    "# Define shallow variational circuit (re-uploading style) and prediction routine\n",
    "def make_device(n_wires, shots=None, use_mixed=False):\n",
    "    backend = \"default.mixed\" if use_mixed else \"lightning.qubit\"\n",
    "    try:\n",
    "        dev = qml.device(backend, wires=n_wires, shots=shots)\n",
    "        J.log(\"device\",\"ok\",f\"{backend} (wires={n_wires}, shots={shots})\")\n",
    "        return dev\n",
    "    except Exception as e:\n",
    "        J.log(\"device\",\"warn\",f\"{backend} unavailable ({e}); fallback to default.qubit\")\n",
    "        return qml.device(\"default.qubit\", wires=n_wires, shots=shots)\n",
    "\n",
    "n_wires = D\n",
    "L = int(os.environ.get(\"VQC_L\",\"2\"))  # layers\n",
    "p_bitflip = float(os.environ.get(\"VQC_P_BITFLIP\",\"0.0\"))\n",
    "p_depol   = float(os.environ.get(\"VQC_P_DEPOL\",\"0.0\"))\n",
    "dev = make_device(n_wires, shots=None, use_mixed=(p_bitflip>0 or p_depol>0))\n",
    "\n",
    "# Robust template import\n",
    "try:\n",
    "    BasicEntanglerLayers = qml.BasicEntanglerLayers\n",
    "except AttributeError:\n",
    "    from pennylane.templates.layers import BasicEntanglerLayers\n",
    "\n",
    "weights = pnp.random.normal(scale=0.15, size=(L, n_wires), requires_grad=True)\n",
    "\n",
    "def layer(x, w):\n",
    "    qml.AngleEmbedding(x, wires=range(n_wires), rotation=\"Y\")\n",
    "    if p_bitflip>0:\n",
    "        for i in range(n_wires): qml.BitFlip(p_bitflip, wires=i)\n",
    "    if p_depol>0:\n",
    "        for i in range(n_wires): qml.DepolarizingChannel(p_depol, wires=i)\n",
    "    BasicEntanglerLayers(w[None, :], wires=range(n_wires))\n",
    "\n",
    "@qml.qnode(dev, interface=\"autograd\")\n",
    "def vqc(x, w):\n",
    "    for l in range(L):\n",
    "        layer(x, w[l])\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "def predict_proba(X, w, as_numpy=False):\n",
    "    vals=[]\n",
    "    for xi in X:\n",
    "        m = vqc(xi, w)              # expectation in [-1,1]\n",
    "        vals.append((1+m)/2)        # map to [0,1]\n",
    "    p = pnp.clip(pnp.stack(vals), 1e-6, 1-1e-6)\n",
    "    return np.asarray(p) if as_numpy else p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38feaf56",
   "metadata": {},
   "source": [
    "# Cell 3 ‚Äî train (Adam + early stopping + safety + journaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00ec6d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01 | loss_tr=0.6310 | loss_va=0.6297\n",
      "epoch 02 | loss_tr=0.6310 | loss_va=0.6299\n",
      "epoch 03 | loss_tr=0.6306 | loss_va=0.6296\n",
      "epoch 04 | loss_tr=0.6309 | loss_va=0.6295\n",
      "epoch 05 | loss_tr=0.6307 | loss_va=0.6292\n",
      "epoch 06 | loss_tr=0.6310 | loss_va=0.6293\n",
      "epoch 07 | loss_tr=0.6313 | loss_va=0.6303\n",
      "epoch 08 | loss_tr=0.6319 | loss_va=0.6305\n",
      "epoch 09 | loss_tr=0.6325 | loss_va=0.6310\n",
      "epoch 10 | loss_tr=0.6313 | loss_va=0.6303\n",
      "epoch 11 | loss_tr=0.6308 | loss_va=0.6296\n",
      "early stopping.\n",
      "‚úÖ [train] Early stopping at epoch 11\n",
      "‚úÖ [train] Finished in 23.6 min; best_val_bce=0.6292; epochs_logged=11\n"
     ]
    }
   ],
   "source": [
    "# Optimize VQC with mini-batch Adam + early stopping on val BCE; log outcomes/problems\n",
    "opt = qml.AdamOptimizer(stepsize=float(os.environ.get(\"VQC_LR\",\"0.05\")))\n",
    "batch_size = int(os.environ.get(\"VQC_BS\",\"64\"))\n",
    "max_epochs = int(os.environ.get(\"VQC_EPOCHS\",\"60\"))\n",
    "patience = int(os.environ.get(\"VQC_PATIENCE\",\"6\"))\n",
    "param_clip = float(os.environ.get(\"VQC_PARAM_CLIP\",\"1.5\"))\n",
    "\n",
    "best_va = float(\"inf\"); best_w = pnp.array(weights, requires_grad=True); no_improve = 0\n",
    "history = []\n",
    "\n",
    "def bce_loss(y_true, p_hat):\n",
    "    return -pnp.mean(y_true*pnp.log(p_hat) + (1-y_true)*pnp.log(1-p_hat))\n",
    "\n",
    "def iterate_minibatches(X, y, bs, shuffle=True):\n",
    "    idx = np.arange(len(y)); \n",
    "    if shuffle: np.random.shuffle(idx)\n",
    "    for i in range(0, len(y), bs):\n",
    "        sl = idx[i:i+bs]; yield X[sl], y[sl]\n",
    "\n",
    "t0 = time.time()\n",
    "for epoch in range(1, max_epochs+1):\n",
    "    try:\n",
    "        for Xb, yb in iterate_minibatches(Xtr, ytr, batch_size):\n",
    "            def cost(w):\n",
    "                y_true = pnp.array(yb, dtype=float)\n",
    "                p_hat  = predict_proba(Xb, w, as_numpy=False)\n",
    "                return bce_loss(y_true, p_hat)\n",
    "            w_new = opt.step(cost, weights)\n",
    "            # parameter clipping to reduce exploding grads / barren-plateau drift\n",
    "            weights = pnp.clip(w_new, -param_clip, param_clip)\n",
    "    except Exception as e:\n",
    "        J.log(\"train\",\"fail\",f\"Exception in optimizer step: {e}\")\n",
    "        break\n",
    "\n",
    "    p_tr = predict_proba(Xtr, weights); p_va = predict_proba(Xva, weights)\n",
    "    loss_tr = float(bce_loss(ytr, p_tr)); loss_va = float(bce_loss(yva, p_va))\n",
    "    if not np.isfinite(loss_tr) or not np.isfinite(loss_va):\n",
    "        J.log(\"train\",\"fail\",\"Non-finite loss encountered; stopping and reverting to best weights so far.\")\n",
    "        break\n",
    "    history.append({\"epoch\":epoch, \"loss_tr\":loss_tr, \"loss_va\":loss_va})\n",
    "    print(f\"epoch {epoch:02d} | loss_tr={loss_tr:.4f} | loss_va={loss_va:.4f}\")\n",
    "\n",
    "    if loss_va + 1e-4 < best_va:\n",
    "        best_va = float(loss_va); best_w = pnp.array(weights, requires_grad=False); no_improve = 0\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= patience:\n",
    "            print(\"early stopping.\"); J.log(\"train\",\"ok\",f\"Early stopping at epoch {epoch}\"); break\n",
    "\n",
    "weights = best_w\n",
    "pd.DataFrame(history).to_csv(RESULTS/\"metrics/vqc_train_curve.csv\", index=False)\n",
    "np.save(RESULTS/\"vqc_weights.npy\", np.array(weights, dtype=float))\n",
    "J.log(\"train\",\"ok\",f\"Finished in {((time.time()-t0)/60):.1f} min; best_val_bce={best_va:.4f}; epochs_logged={len(history)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e090a3",
   "metadata": {},
   "source": [
    "# Cell 4 ‚Äî metrics (val-optimal threshold, full matrices, plots, docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e14a02f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ [threshold] VQC: thr=0.05 (val F1=0.922)\n",
      "acc             0.865516\n",
      "prec            0.865516\n",
      "rec                  1.0\n",
      "f1               0.92791\n",
      "roc_auc         0.540335\n",
      "pr_auc          0.880499\n",
      "specificity          0.0\n",
      "balanced_acc         0.5\n",
      "mcc                  0.0\n",
      "thr                 0.05\n",
      "tp                  3559\n",
      "tn                     0\n",
      "fp                   553\n",
      "fn                     0\n",
      "support             4112\n",
      "model                VQC\n",
      "split               test\n",
      "‚úÖ [eval] VQC: test F1=0.928, AUC=0.540, PR-AUC=0.880, thr=0.05\n"
     ]
    }
   ],
   "source": [
    "# Determine threshold on val; report rich metrics for all splits; save plots & reports\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def choose_threshold(y_val, p_val, name=\"VQC\"):\n",
    "    grid = np.linspace(0.05, 0.95, 37)\n",
    "    best_thr, best_f1 = 0.5, -1\n",
    "    for t in grid:\n",
    "        f1 = f1_score(y_val, (p_val>=t).astype(int), zero_division=0)\n",
    "        if f1 > best_f1: best_f1, best_thr = float(f1), float(t)\n",
    "    if np.isnan(best_f1):\n",
    "        J.log(\"threshold\",\"warn\",f\"{name}: F1 undefined on val; using thr=0.5\")\n",
    "        return 0.5\n",
    "    J.log(\"threshold\",\"ok\",f\"{name}: thr={best_thr:.2f} (val F1={best_f1:.3f})\")\n",
    "    return best_thr\n",
    "\n",
    "def extended_metrics(y_true, p, thr):\n",
    "    yhat = (p>=thr).astype(int)\n",
    "    acc = accuracy_score(y_true, yhat)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, yhat, average=\"binary\", zero_division=0)\n",
    "    try: auc = roc_auc_score(y_true, p)\n",
    "    except Exception: auc = float(\"nan\")\n",
    "    try: ap = average_precision_score(y_true, p)\n",
    "    except Exception: ap = float(\"nan\")\n",
    "    cm = confusion_matrix(y_true, yhat, labels=[0,1])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    tnr = tn/(tn+fp) if (tn+fp) else float(\"nan\")\n",
    "    bal = balanced_accuracy_score(y_true, yhat)\n",
    "    mcc = matthews_corrcoef(y_true, yhat) if len(np.unique(y_true))==2 else float(\"nan\")\n",
    "    rep = classification_report(y_true, yhat, output_dict=True, zero_division=0)\n",
    "    return {\n",
    "        \"acc\":acc, \"prec\":prec, \"rec\":rec, \"f1\":f1, \"roc_auc\":auc, \"pr_auc\":ap,\n",
    "        \"specificity\":tnr, \"balanced_acc\":bal, \"mcc\":mcc, \"thr\":thr,\n",
    "        \"tp\":int(tp), \"tn\":int(tn), \"fp\":int(fp), \"fn\":int(fn), \"support\":int(len(y_true)),\n",
    "    }, cm, rep\n",
    "\n",
    "def save_cm_csv(cm, out_csv, normalized=False):\n",
    "    if normalized:\n",
    "        cm = cm.astype(np.float64); rs = cm.sum(axis=1, keepdims=True); cm = np.divide(cm, np.where(rs==0,1,rs))\n",
    "    pd.DataFrame(cm, index=[\"true_0\",\"true_1\"], columns=[\"pred_0\",\"pred_1\"]).to_csv(out_csv, index=True)\n",
    "\n",
    "def plot_roc(y_true, p, title, out_png):\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    try:\n",
    "        fpr, tpr, _ = roc_curve(y_true, p); roc_auc = auc(fpr, tpr)\n",
    "        plt.figure(); plt.plot(fpr, tpr, label=f\"AUC={roc_auc:.3f}\")\n",
    "        plt.plot([0,1],[0,1],'--'); plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(title); plt.legend(); plt.tight_layout()\n",
    "        plt.savefig(out_png, dpi=150); plt.close()\n",
    "    except Exception as e:\n",
    "        J.log(\"plot\",\"warn\",f\"ROC plot skipped: {e}\")\n",
    "\n",
    "def plot_pr(y_true, p, title, out_png):\n",
    "    from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "    try:\n",
    "        pr, rc, _ = precision_recall_curve(y_true, p); ap = average_precision_score(y_true, p)\n",
    "        plt.figure(); plt.plot(rc, pr, label=f\"AP={ap:.3f}\")\n",
    "        plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(title); plt.legend(); plt.tight_layout()\n",
    "        plt.savefig(out_png, dpi=150); plt.close()\n",
    "    except Exception as e:\n",
    "        J.log(\"plot\",\"warn\",f\"PR plot skipped: {e}\")\n",
    "\n",
    "# Probabilities\n",
    "p_tr = predict_proba(Xtr, weights, as_numpy=True)\n",
    "p_va = predict_proba(Xva, weights, as_numpy=True)\n",
    "p_te = predict_proba(Xte, weights, as_numpy=True)\n",
    "\n",
    "thr = choose_threshold(yva, p_va, name=\"VQC\")\n",
    "\n",
    "splits = {\"train\":(ytr,p_tr), \"val\":(yva,p_va), \"test\":(yte,p_te)}\n",
    "rows, reports, cms = [], {}, {}\n",
    "for split,(yt,pt) in splits.items():\n",
    "    m, cm, rep = extended_metrics(yt, pt, thr)\n",
    "    m.update({\"model\":\"VQC\",\"split\":split})\n",
    "    rows.append(m); cms[split]=cm; reports[split]=rep\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(RESULTS/\"metrics/vqc_metrics.csv\", index=False)\n",
    "\n",
    "# Confusion matrices\n",
    "for split, cm in cms.items():\n",
    "    save_cm_csv(cm, RESULTS/f\"metrics/vqc_cm_{split}.csv\", normalized=False)\n",
    "    save_cm_csv(cm, RESULTS/f\"metrics/vqc_cm_{split}_norm.csv\", normalized=True)\n",
    "\n",
    "# Classification report JSON\n",
    "with open(RESULTS/\"metrics/vqc_classification_reports.json\",\"w\",encoding=\"utf-8\") as f:\n",
    "    json.dump(reports, f, indent=2)\n",
    "\n",
    "# Plots (test)\n",
    "plot_roc(yte, p_te, \"VQC ‚Äî ROC (test)\", RESULTS/\"plots/vqc_roc_test.png\")\n",
    "plot_pr (yte, p_te, \"VQC ‚Äî PR (test)\",  RESULTS/\"plots/vqc_pr_test.png\")\n",
    "\n",
    "# Console + journal summary (no backslashes in f-strings)\n",
    "row_test = df.loc[df[\"split\"]==\"test\"].iloc[0]\n",
    "print(row_test.to_string())\n",
    "J.log(\"eval\",\"ok\",\n",
    "      f\"VQC: test F1={row_test['f1']:.3f}, AUC={row_test['roc_auc']:.3f}, PR-AUC={row_test['pr_auc']:.3f}, thr={thr:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d263da",
   "metadata": {},
   "source": [
    "# (Optional) Cell 5 ‚Äî Per-dataset diagnostics (if ds_idx available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "378acb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ [per-dataset] Saved per-dataset test metrics for 13 dataset(s).\n"
     ]
    }
   ],
   "source": [
    "# Evaluate generalization per dataset on TEST split only (reuse global thr)\n",
    "if ds_idx is None:\n",
    "    J.log(\"per-dataset\",\"warn\",\"ds_idx not found ‚Äî skipping per-dataset diagnostics.\")\n",
    "else:\n",
    "    rows = []\n",
    "    uniq = sorted(np.unique(ds_idx[te_idx]))\n",
    "    for d in uniq:\n",
    "        name = ds_map.get(d, f\"ds_{d}\") if ds_map else f\"ds_{d}\"\n",
    "        mask = (ds_idx[te_idx] == d)\n",
    "        if mask.sum() == 0: continue\n",
    "        y_true = yte[mask]; p_sub = p_te[mask]\n",
    "        m, cm, _ = extended_metrics(y_true, p_sub, thr)\n",
    "        m.update({\"model\":\"VQC\",\"dataset\":name,\"n\":int(mask.sum())})\n",
    "        rows.append(m)\n",
    "    df_per = pd.DataFrame(rows)\n",
    "    df_per.to_csv(RESULTS/\"metrics/vqc_per_dataset_test.csv\", index=False)\n",
    "    J.log(\"per-dataset\",\"ok\",f\"Saved per-dataset test metrics for {len(df_per)} dataset(s).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dafb0ec",
   "metadata": {},
   "source": [
    "# Cell 6 ‚Äî Save run journal (what worked, what didn‚Äôt, and why)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b689fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RUN SUMMARY ===\n",
      "No warnings or failures.\n",
      "üìù Saved journal:\n",
      "  - results\\logs\\vqc_20250917_184000.md\n",
      "  - results\\logs\\vqc_20250917_184000.json\n",
      "üì¶ Metrics in: results\\metrics  |  Plots in: results\\plots\n"
     ]
    }
   ],
   "source": [
    "ts = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "base = RESULTS/\"logs\"/f\"vqc_{ts}\"\n",
    "\n",
    "issues = []\n",
    "for e in J.events:\n",
    "    if e[\"status\"] in (\"warn\",\"fail\"):\n",
    "        issues.append(f\"- [{e['step']}] {e['message']}\")\n",
    "rollup = \"No warnings or failures.\" if not issues else \"Issues observed:\\n\" + \"\\n\".join(issues)\n",
    "print(\"\\n=== RUN SUMMARY ===\\n\" + rollup)\n",
    "\n",
    "J.save(base)\n",
    "(RESULTS/\"logs\"/f\"vqc_{ts}_summary.txt\").write_text(rollup, encoding=\"utf-8\")\n",
    "print(f\"üì¶ Metrics in: {RESULTS/'metrics'}  |  Plots in: {RESULTS/'plots'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
