{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a58188c",
   "metadata": {},
   "source": [
    "# 07_reporting.ipynb — improved, explainable reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e79112f",
   "metadata": {},
   "source": [
    "# Cell 0 — perf env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f777403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ.setdefault(\"OMP_NUM_THREADS\", \"8\")\n",
    "os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"8\")\n",
    "os.environ.setdefault(\"MKL_NUM_THREADS\", \"8\")\n",
    "os.environ.setdefault(\"NUMEXPR_NUM_THREADS\", \"8\")\n",
    "'8'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830b0f88",
   "metadata": {},
   "source": [
    "# Cell 1 — load metrics, sweeps, caches, helpers (enhanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22169e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json, sys, platform, warnings, math, re\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, average_precision_score, confusion_matrix\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "ROOT = Path(\".\")\n",
    "RESULTS = ROOT/\"results\"\n",
    "METRICS = RESULTS/\"metrics\"\n",
    "FIGS    = RESULTS/\"figures\"\n",
    "TABLES  = RESULTS/\"tables\"\n",
    "REPORT  = RESULTS/\"report\"\n",
    "LOGS    = RESULTS/\"logs\"\n",
    "for p in [FIGS, TABLES, REPORT]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def safe_load_csv(path: Path) -> pd.DataFrame:\n",
    "    if not path.exists():\n",
    "        print(\"! missing:\", path)\n",
    "        return pd.DataFrame()\n",
    "    try:\n",
    "        return pd.read_csv(path)\n",
    "    except Exception as e:\n",
    "        print(\"! could not read:\", path, e)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def safe_load_json(path: Path, default=None):\n",
    "    if not path.exists(): return default\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f: return json.load(f)\n",
    "    except Exception: return default\n",
    "\n",
    "# ---- Core metrics from all notebooks ----\n",
    "combined = safe_load_csv(METRICS/\"combined.csv\")            # 06 notebook consolidated\n",
    "m_qsvm   = safe_load_csv(METRICS/\"qsvm_kernel_metrics.csv\") # 03 QSVM precomputed kernel\n",
    "m_vqc    = safe_load_csv(METRICS/\"vqc.csv\")                 # 04 VQC (if exported there)\n",
    "m_svmk   = safe_load_csv(METRICS/\"svm_kmer.csv\") if (METRICS/\"svm_kmer.csv\").exists() else pd.DataFrame()\n",
    "m_svm1   = safe_load_csv(METRICS/\"svm_onehot_flat.csv\") if (METRICS/\"svm_onehot_flat.csv\").exists() else pd.DataFrame()\n",
    "ns_vqc   = safe_load_csv(METRICS/\"noise_sweep_vqc.csv\")\n",
    "ns_qsvm  = safe_load_csv(METRICS/\"noise_sweep_qsvm.csv\")\n",
    "\n",
    "# ---- Caches for ROC/CM ----\n",
    "ROC_DIR = RESULTS / \"roc_cache\"\n",
    "CM_DIR  = RESULTS / \"cm_cache\"\n",
    "\n",
    "# ---- Optional run-timing report (from 06 sweep) ----\n",
    "timing = {}\n",
    "rr = METRICS / \"noise_sweep_run_report.json\"\n",
    "if rr.exists():\n",
    "    timing = safe_load_json(rr, {}).get(\"timing\", {})\n",
    "\n",
    "# ---- Dataset/meta (optional) ----\n",
    "enc_meta = safe_load_json(ROOT/\"data/processed/meta.json\", {})\n",
    "appx_env = safe_load_json(RESULTS/\"appendix/environment.json\", {})\n",
    "\n",
    "# ---- McNemar tests (optional) ----\n",
    "mcnemar_stats = safe_load_json(RESULTS/\"stats/mcnemar.json\", {})\n",
    "\n",
    "# ---- Gather RunJournal events across notebooks (printable limitations/problems) ----\n",
    "def collect_journal_events(log_root: Path) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    if not log_root.exists(): return pd.DataFrame(columns=[\"ts\",\"step\",\"status\",\"message\",\"source\"])\n",
    "    for p in sorted(log_root.glob(\"**/*.json\")):\n",
    "        if not re.search(r\"(qsvm|noise|vqc|kernel|baseline|analysis|robustness)\", p.name, re.I):\n",
    "            continue\n",
    "        data = safe_load_json(p, [])\n",
    "        if isinstance(data, list):\n",
    "            for r in data:\n",
    "                r = {**r, \"source\": p.name}\n",
    "                rows.append(r)\n",
    "    if not rows: \n",
    "        return pd.DataFrame(columns=[\"ts\",\"step\",\"status\",\"message\",\"source\"])\n",
    "    df = pd.DataFrame(rows)\n",
    "    keep = [c for c in [\"ts\",\"step\",\"status\",\"message\",\"source\"] if c in df.columns]\n",
    "    df = df[keep].sort_values(\"ts\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "journal = collect_journal_events(LOGS)\n",
    "\n",
    "# ---- Helpers ----\n",
    "def pick_test(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df.empty: return df\n",
    "    if \"split\" in df.columns:\n",
    "        return df[df[\"split\"].str.lower()==\"test\"].copy()\n",
    "    return df\n",
    "\n",
    "def ensure_columns(df, cols):\n",
    "    out = df.copy()\n",
    "    for c in cols:\n",
    "        if c not in out.columns: out[c] = np.nan\n",
    "    return out\n",
    "\n",
    "# ---- Build unified test table (one row per model) ----\n",
    "cands = []\n",
    "if not combined.empty:\n",
    "    cands.append(pick_test(combined))\n",
    "for name, df in [(\"QSVM_kernel\", m_qsvm), (\"VQC\", m_vqc), (\"SVM_kmer\", m_svmk), (\"SVM_onehot\", m_svm1)]:\n",
    "    if not df.empty:\n",
    "        z = df.copy()\n",
    "        if \"model\" not in z.columns:\n",
    "            z[\"model\"] = name\n",
    "        cands.append(pick_test(z))\n",
    "\n",
    "if not cands:\n",
    "    raise RuntimeError(\"No metrics found. Run 02/03/04/06 first.\")\n",
    "\n",
    "test_all = pd.concat(cands, ignore_index=True)\n",
    "keep = [\"model\",\"acc\",\"prec\",\"rec\",\"f1\",\"auc\",\"pr_auc\",\"specificity\",\"balanced_acc\",\"mcc\"]\n",
    "test_all = ensure_columns(test_all, keep)\n",
    "\n",
    "test_all = (test_all[keep]\n",
    "            .dropna(subset=[\"model\"])\n",
    "            .drop_duplicates(subset=[\"model\"], keep=\"last\")\n",
    "            .sort_values(\"f1\", ascending=False)\n",
    "            .reset_index(drop=True))\n",
    "\n",
    "test_all.to_csv(METRICS/\"summary_test.csv\", index=False)\n",
    "\n",
    "# ---- Deltas vs baseline (SVM_kmer), if present ----\n",
    "if \"SVM_kmer\" in test_all[\"model\"].values:\n",
    "    base = test_all.set_index(\"model\").loc[\"SVM_kmer\"]\n",
    "    for m in test_all[\"model\"].values:\n",
    "        if m == \"SVM_kmer\": continue\n",
    "        for k in [\"acc\",\"prec\",\"rec\",\"f1\",\"auc\",\"pr_auc\",\"specificity\",\"balanced_acc\",\"mcc\"]:\n",
    "            v = test_all.loc[test_all[\"model\"]==m, k].values[0]\n",
    "            test_all.loc[test_all[\"model\"]==m, f\"Δ{k}\"] = (v - base[k]) if (not np.isnan(v) and not np.isnan(base[k])) else np.nan\n",
    "\n",
    "# ---- Best noise configs ----\n",
    "def best_noise(df: pd.DataFrame, topn=5):\n",
    "    if df.empty: return pd.DataFrame()\n",
    "    t = df[df[\"split\"]==\"test\"].copy()\n",
    "    if t.empty: return pd.DataFrame()\n",
    "    cols = [c for c in [\"shots\",\"pflip\",\"pdepol\",\"anchors\",\"S_NOISE\"] if c in t.columns]\n",
    "    return (t.groupby(cols)[\"f1\"].mean().reset_index().sort_values(\"f1\", ascending=False).head(topn))\n",
    "\n",
    "best_vqc  = best_noise(ns_vqc, 5)\n",
    "best_qsvm = best_noise(ns_qsvm, 5)\n",
    "\n",
    "print(\"Summary rows:\", len(test_all))\n",
    "display(test_all)\n",
    "print(\"\\nBest VQC noise configs:\");  display(best_vqc)\n",
    "print(\"\\nBest QSVM noise configs:\"); display(best_qsvm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b148ee54",
   "metadata": {},
   "source": [
    "# Cell 2 — LaTeX table + richer figures (ROC, PR, CM, bars, noise heatmaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9cc778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LaTeX export (richer columns if available) ---\n",
    "latex_cols = [c for c in [\"acc\",\"prec\",\"rec\",\"f1\",\"auc\",\"pr_auc\",\"specificity\",\"balanced_acc\",\"mcc\"] if c in test_all.columns]\n",
    "latex = test_all[[\"model\"]+latex_cols].rename(columns={\n",
    "    \"acc\":\"Accuracy\",\"prec\":\"Precision\",\"rec\":\"Recall\",\"f1\":\"F1\",\"auc\":\"ROC-AUC\",\n",
    "    \"pr_auc\":\"PR-AUC\",\"specificity\":\"Specificity\",\"balanced_acc\":\"Balanced-Acc\",\"mcc\":\"MCC\"\n",
    "}).set_index(\"model\")\n",
    "with open(TABLES/\"summary_test.tex\",\"w\") as f:\n",
    "    f.write(latex.to_latex(float_format=\"%.3f\", escape=True))\n",
    "print(\"Wrote:\", TABLES/\"summary_test.tex\")\n",
    "\n",
    "# --- ROC & PR curves from cache (if available) ---\n",
    "if ROC_DIR.exists() and (ROC_DIR/\"y_test.npy\").exists():\n",
    "    y_test = np.load(ROC_DIR/\"y_test.npy\")\n",
    "    items = []\n",
    "    for name in [\"svm_kmer\",\"svm_onehot\",\"qsvm_kernel\",\"vqc\"]:\n",
    "        pfile = ROC_DIR / f\"probs_{name}.npy\"\n",
    "        if pfile.exists():\n",
    "            items.append((name, np.load(pfile)))\n",
    "    if items:\n",
    "        # ROC\n",
    "        fig, ax = plt.subplots(figsize=(6,5))\n",
    "        for name, probs in items:\n",
    "            fpr, tpr, _ = roc_curve(y_test, probs)\n",
    "            auc = roc_auc_score(y_test, probs)\n",
    "            ax.plot(fpr, tpr, label=f\"{name} (AUC={auc:.3f})\")\n",
    "        ax.plot([0,1],[0,1],\"--\", lw=1)\n",
    "        ax.set_xlabel(\"False Positive Rate\"); ax.set_ylabel(\"True Positive Rate\")\n",
    "        ax.set_title(\"ROC (test)\"); ax.legend()\n",
    "        fig.tight_layout(); fig.savefig(FIGS/\"roc_test.png\", dpi=200); plt.show()\n",
    "\n",
    "        # PR\n",
    "        fig, ax = plt.subplots(figsize=(6,5))\n",
    "        for name, probs in items:\n",
    "            prec, rec, _ = precision_recall_curve(y_test, probs)\n",
    "            ap = average_precision_score(y_test, probs)\n",
    "            ax.plot(rec, prec, label=f\"{name} (AP={ap:.3f})\")\n",
    "        ax.set_xlabel(\"Recall\"); ax.set_ylabel(\"Precision\")\n",
    "        ax.set_title(\"PR (test)\"); ax.legend()\n",
    "        fig.tight_layout(); fig.savefig(FIGS/\"pr_test.png\", dpi=200); plt.show()\n",
    "    else:\n",
    "        print(\"No ROC/PR cache found.\")\n",
    "else:\n",
    "    print(\"No ROC cache directory or y_test.npy.\")\n",
    "\n",
    "# --- Confusion matrices (if cached predicted labels) ---\n",
    "try:\n",
    "    if CM_DIR.exists() and (CM_DIR/\"y_true.json\").exists():\n",
    "        import json as _json\n",
    "        with open(CM_DIR/\"y_true.json\") as f:\n",
    "            y_true = np.array(_json.load(f))\n",
    "        for name in [\"svm_kmer\",\"svm_onehot\",\"qsvm_kernel\",\"vqc\"]:\n",
    "            yp = CM_DIR / f\"y_pred_{name}.json\"\n",
    "            if not yp.exists(): \n",
    "                continue\n",
    "            with open(yp) as f:\n",
    "                y_pred = np.array(_json.load(f))\n",
    "            cm = confusion_matrix(y_true, y_pred)\n",
    "            fig, ax = plt.subplots(figsize=(3.8,3.3))\n",
    "            im = ax.imshow(cm)\n",
    "            ax.set_title(f\"Confusion Matrix — {name} (test)\")\n",
    "            ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\")\n",
    "            for (i,j), v in np.ndenumerate(cm):\n",
    "                ax.text(j, i, int(v), ha=\"center\", va=\"center\", color=(\"white\" if im.norm(v)>0.5 else \"black\"))\n",
    "            fig.colorbar(im, ax=ax, shrink=0.8)\n",
    "            fig.tight_layout(); fig.savefig(FIGS/f\"cm_{name}.png\", dpi=200); plt.show()\n",
    "except Exception as e:\n",
    "    print(\"CM render skipped:\", e)\n",
    "\n",
    "# --- Bar chart for F1 ---\n",
    "if not test_all.empty:\n",
    "    fig, ax = plt.subplots(figsize=(7,4))\n",
    "    ax.bar(test_all[\"model\"], test_all[\"f1\"])\n",
    "    ax.set_ylim(0, 1); ax.set_ylabel(\"F1 (test)\"); ax.set_title(\"Test F1 by model\")\n",
    "    for i, v in enumerate(test_all[\"f1\"].values):\n",
    "        ax.text(i, v + 0.02, f\"{v:.2f}\", ha=\"center\", va=\"bottom\")\n",
    "    plt.xticks(rotation=15, ha=\"right\"); plt.tight_layout()\n",
    "    fig.savefig(FIGS/\"bar_f1_test.png\", dpi=200); plt.show()\n",
    "\n",
    "# --- Heatmaps for noise sweeps (if available) ---\n",
    "def heatmap_from_pivot(df, name):\n",
    "    if df.empty:\n",
    "        print(f\"No data for {name} heatmap.\"); return\n",
    "    t = df[df[\"split\"]==\"test\"][[\"shots\",\"pflip\",\"pdepol\",\"f1\"]].copy()\n",
    "    if t.empty: \n",
    "        print(f\"No test split in {name}.\"); return\n",
    "    for sh in sorted(t[\"shots\"].unique()):\n",
    "        sub = t[t[\"shots\"]==sh].copy()\n",
    "        cols = sorted(sub[\"pdepol\"].unique()); rows = sorted(sub[\"pflip\"].unique())\n",
    "        M = np.zeros((len(rows), len(cols))) + np.nan\n",
    "        for i, pf in enumerate(rows):\n",
    "            for j, pd in enumerate(cols):\n",
    "                vals = sub[(sub[\"pflip\"]==pf) & (sub[\"pdepol\"]==pd)][\"f1\"].values\n",
    "                if len(vals): M[i,j] = np.mean(vals)\n",
    "        fig, ax = plt.subplots(figsize=(5.4,4.2))\n",
    "        im = ax.imshow(M, aspect=\"auto\", origin=\"upper\")\n",
    "        ax.set_xticks(range(len(cols))); ax.set_xticklabels([f\"{c:.3f}\" for c in cols])\n",
    "        ax.set_yticks(range(len(rows))); ax.set_yticklabels([f\"{r:.3f}\" for r in rows])\n",
    "        ax.set_xlabel(\"p_depol\"); ax.set_ylabel(\"p_flip\"); ax.set_title(f\"{name} F1 — shots={sh}\")\n",
    "        for (i,j), v in np.ndenumerate(M):\n",
    "            if not np.isnan(v):\n",
    "                ax.text(j, i, f\"{v:.2f}\", ha=\"center\", va=\"center\", color=(\"white\" if im.norm(v)>0.6 else \"black\"))\n",
    "        fig.colorbar(im, ax=ax, shrink=0.8)\n",
    "        fig.tight_layout(); fig.savefig(FIGS/f\"heat_{name}_shots{sh}.png\", dpi=200); plt.show()\n",
    "\n",
    "heatmap_from_pivot(ns_vqc,  \"VQC\")\n",
    "heatmap_from_pivot(ns_qsvm, \"QSVM\")\n",
    "print(\"Figures ready in:\", FIGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b977912e",
   "metadata": {},
   "source": [
    "# Cell 3 — executive summary & markdown (adds limitations/problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d781595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executive summary (Markdown + file)\n",
    "lines = []\n",
    "lines.append(\"# Results Summary\\n\")\n",
    "\n",
    "if not test_all.empty:\n",
    "    best = test_all.iloc[0]\n",
    "    base_txt = \"\"\n",
    "    if \"SVM_kmer\" in test_all[\"model\"].values:\n",
    "        base = test_all.set_index(\"model\").loc[\"SVM_kmer\"]\n",
    "        best_delta = best[\"f1\"] - base[\"f1\"] if not np.isnan(base[\"f1\"]) else np.nan\n",
    "        base_txt = f\" vs SVM_kmer ΔF1={best_delta:+.3f}\" if not np.isnan(best_delta) else \"\"\n",
    "    lines.append(f\"- **Best test F1:** {best['f1']:.3f} ({best['model']}){base_txt}; \"\n",
    "                 f\"Acc={best['acc']:.3f}, Prec={best['prec']:.3f}, Rec={best['rec']:.3f}, \"\n",
    "                 f\"ROC-AUC={best['auc']:.3f}, PR-AUC={best.get('pr_auc',np.nan):.3f}\\n\")\n",
    "else:\n",
    "    lines.append(\"- Metrics not found; run training/evaluation notebooks first.\\n\")\n",
    "\n",
    "# Dataset/Encoding\n",
    "if enc_meta:\n",
    "    lines.append(\"## Dataset/Encoding\\n\")\n",
    "    lines.append(f\"- Accession: `{enc_meta.get('accession','?')}`\")\n",
    "    lines.append(f\"- Window: {enc_meta.get('window','?')}  |  Stride: {enc_meta.get('stride','?')}\")\n",
    "    lines.append(f\"- Total samples: {enc_meta.get('n_samples','?')}\\n\")\n",
    "\n",
    "# Noise & Shots — Top configs\n",
    "if not ns_vqc.empty or not ns_qsvm.empty:\n",
    "    lines.append(\"## Noise & Shots — Top configs\")\n",
    "    if 'best_vqc' in globals() and not best_vqc.empty:\n",
    "        lines.append(\"**VQC (by mean test F1):**\")\n",
    "        for r in best_vqc.itertuples():\n",
    "            lines.append(f\"- shots={r.shots}, pflip={r.pflip}, pdepol={r.pdepol} → F1={r.f1:.3f}\")\n",
    "    if 'best_qsvm' in globals() and not best_qsvm.empty:\n",
    "        lines.append(\"**QSVM (by mean test F1):**\")\n",
    "        for r in best_qsvm.itertuples():\n",
    "            extra = []\n",
    "            if hasattr(r, \"anchors\"): extra.append(f\"anchors={r.anchors}\")\n",
    "            if hasattr(r, \"S_NOISE\"): extra.append(f\"S_NOISE={r.S_NOISE}\")\n",
    "            lines.append(f\"- shots={r.shots}, pflip={r.pflip}, pdepol={r.pdepol}\"\n",
    "                         + (\", \" + \", \".join(extra) if extra else \"\")\n",
    "                         + f\" → F1={r.f1:.3f}\")\n",
    "\n",
    "# Limitations & Problems from journals\n",
    "if not journal.empty:\n",
    "    lines.append(\"\\n## Limitations & Problems (from run journals)\")\n",
    "    for _, r in journal[journal[\"status\"].isin([\"warn\",\"fail\"])].iterrows():\n",
    "        lines.append(f\"- [{r['status'].upper()}:{r['step']}] {r['message']} (source: {r['source']})\")\n",
    "else:\n",
    "    lines.append(\"\\n## Limitations & Problems\\n- No warnings or failures recorded in journals.\")\n",
    "\n",
    "# Artifacts\n",
    "lines.append(\"\\n## Artifacts\")\n",
    "lines.append(\"- `results/metrics/summary_test.csv`\")\n",
    "lines.append(\"- `results/figures/roc_test.png`, `pr_test.png`, `bar_f1_test.png`, `cm_*.png`, `heat_*_shots*.png`\")\n",
    "lines.append(\"- `results/tables/summary_test.tex`\")\n",
    "lines.append(\"- `results/report/DNA_QML_Results_Report.docx` / `.pdf`\")\n",
    "\n",
    "(REPORT / \"SUMMARY.md\").write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "print(\"Wrote:\", REPORT/\"SUMMARY.md\")\n",
    "print((REPORT/\"SUMMARY.md\").read_text()[:800], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af31504",
   "metadata": {},
   "source": [
    "# Cell 4 — prep artifacts for document builders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f310d438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather figure paths safely (if exist)\n",
    "def _maybe(p): \n",
    "    p = Path(p)\n",
    "    return str(p) if p.exists() else None\n",
    "\n",
    "ART = {\n",
    "    \"ROC (test)\":               _maybe(FIGS/\"roc_test.png\"),\n",
    "    \"PR (test)\":                _maybe(FIGS/\"pr_test.png\"),\n",
    "    \"F1 bar (test)\":            _maybe(FIGS/\"bar_f1_test.png\"),\n",
    "    \"Confusion (svm_kmer)\":     _maybe(FIGS/\"cm_svm_kmer.png\"),\n",
    "    \"Confusion (svm_onehot)\":   _maybe(FIGS/\"cm_svm_onehot.png\"),\n",
    "    \"Confusion (qsvm_kernel)\":  _maybe(FIGS/\"cm_qsvm_kernel.png\"),\n",
    "    \"Confusion (vqc)\":          _maybe(FIGS/\"cm_vqc.png\"),\n",
    "}\n",
    "\n",
    "# plus any heatmaps generated\n",
    "for p in FIGS.glob(\"heat_*_shots*.png\"):\n",
    "    ART[p.stem] = str(p)\n",
    "\n",
    "print(\"Figures collected:\", len([v for v in ART.values() if v]))\n",
    "list(ART.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afb2ce1",
   "metadata": {},
   "source": [
    "# Cell 5 — safe imports + helpers for DOCX/PDF (adds richer tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434cb0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safe import & helpers\n",
    "def ensure_imports():\n",
    "    \"\"\"Import python-docx & reportlab safely. Returns (DocxDocument, Inches, Pt, WD_ALIGN, reportlab_ok).\"\"\"\n",
    "    DocxDocument = Inches = Pt = WD_ALIGN_PARAGRAPH = None\n",
    "    reportlab_ok = True\n",
    "    try:\n",
    "        from docx import Document as DocxDocument\n",
    "        from docx.shared import Inches, Pt\n",
    "        from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "        from docx.enum.section import WD_ORIENT\n",
    "        from docx.oxml.ns import qn\n",
    "        from docx.oxml import OxmlElement\n",
    "    except Exception as e:\n",
    "        try:\n",
    "            import subprocess, sys as _sys\n",
    "            subprocess.check_call([_sys.executable, \"-m\", \"pip\", \"install\", \"python-docx\"])\n",
    "            from docx import Document as DocxDocument\n",
    "            from docx.shared import Inches, Pt\n",
    "            from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "            from docx.enum.section import WD_ORIENT\n",
    "            from docx.oxml.ns import qn\n",
    "            from docx.oxml import OxmlElement\n",
    "        except Exception as ee:\n",
    "            print(\"! python-docx not available:\", ee)\n",
    "            DocxDocument = Inches = Pt = WD_ALIGN_PARAGRAPH = None\n",
    "\n",
    "    try:\n",
    "        from reportlab.lib.pagesizes import A4, landscape\n",
    "        from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image as RLImage, Table, TableStyle, PageBreak\n",
    "        from reportlab.lib.styles import getSampleStyleSheet\n",
    "        from reportlab.lib.units import inch\n",
    "        from reportlab.lib import colors\n",
    "    except Exception:\n",
    "        reportlab_ok = False\n",
    "\n",
    "    globals().update(locals())\n",
    "    return DocxDocument, Inches, Pt, WD_ALIGN_PARAGRAPH, reportlab_ok\n",
    "\n",
    "DocxDocument, Inches, Pt, WD_ALIGN_PARAGRAPH, REPORTLAB_OK = ensure_imports()\n",
    "\n",
    "def _sys_info():\n",
    "    import numpy, pandas, sklearn\n",
    "    return {\n",
    "        \"Python\": sys.version.split()[0],\n",
    "        \"Platform\": f\"{platform.system()} {platform.release()} ({platform.machine()})\",\n",
    "        \"NumPy\": numpy.__version__,\n",
    "        \"Pandas\": pandas.__version__,\n",
    "        \"Scikit-learn\": sklearn.__version__,\n",
    "        \"Matplotlib\": plt.matplotlib.__version__,\n",
    "    }\n",
    "\n",
    "def _fmt_secs(sec):\n",
    "    return f\"{sec/60:.1f} min\" if isinstance(sec,(int,float)) and sec >= 60 else f\"{sec:.1f} s\" if isinstance(sec,(int,float)) else \"-\"\n",
    "\n",
    "def df_to_docx_table(doc, df, style=\"Light List Accent 1\"):\n",
    "    cols = list(df.columns)\n",
    "    tbl = doc.add_table(rows=1, cols=len(cols))\n",
    "    hdr = tbl.rows[0].cells\n",
    "    for j, c in enumerate(cols):\n",
    "        hdr[j].text = str(c)\n",
    "    for _, row in df.iterrows():\n",
    "        cells = tbl.add_row().cells\n",
    "        for j, c in enumerate(cols):\n",
    "            v = row[c]\n",
    "            cells[j].text = f\"{v:.3f}\" if isinstance(v, float) else str(v)\n",
    "    tbl.style = style\n",
    "    return tbl\n",
    "\n",
    "def add_toc_field(doc):\n",
    "    \"\"\"Insert a Word TOC field that updates on open (References → Update Table in Word).\"\"\"\n",
    "    try:\n",
    "        from docx.oxml import OxmlElement\n",
    "        from docx.oxml.ns import qn\n",
    "        p = doc.add_paragraph()\n",
    "        r = p.add_run()\n",
    "        fld = OxmlElement('w:fldSimple')\n",
    "        fld.set(qn('w:instr'), 'TOC \\\\o \"1-3\" \\\\h \\\\z \\\\u')\n",
    "        r._r.append(fld)\n",
    "    except Exception as e:\n",
    "        doc.add_paragraph(\"(TOC field could not be inserted automatically)\")\n",
    "\n",
    "def add_section_landscape(doc):\n",
    "    from docx.enum.section import WD_ORIENT\n",
    "    section = doc.add_section()\n",
    "    section.orientation = WD_ORIENT.LANDSCAPE\n",
    "    new_w, new_h = section.page_height, section.page_width\n",
    "    section.page_width, section.page_height = new_w, new_h\n",
    "    return section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63acf6d",
   "metadata": {},
   "source": [
    "# Cell 6 — build advanced DOCX + PDF and preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3bf580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "DOCX_PATH = REPORT / \"DNA_QML_Results_Report.docx\"\n",
    "PDF_PATH  = REPORT / \"DNA_QML_Results_Report.pdf\"\n",
    "\n",
    "if DocxDocument is None:\n",
    "    raise RuntimeError(\"python-docx not available. Please install python-docx and re-run this cell.\")\n",
    "\n",
    "doc = DocxDocument()\n",
    "\n",
    "# ----- Cover -----\n",
    "title = doc.add_heading(\"DNA QML — Results Report\", level=0)\n",
    "title.alignment = 1\n",
    "doc.add_paragraph(datetime.now().strftime(\"%Y-%m-%d %H:%M\")).alignment = 1\n",
    "envp = doc.add_paragraph()\n",
    "for k, v in _sys_info().items():\n",
    "    envp.add_run(f\"{k}: {v}\\n\").font.size = Pt(10)\n",
    "doc.add_page_break()\n",
    "\n",
    "# ----- TOC -----\n",
    "doc.add_heading(\"Table of Contents\", level=1)\n",
    "add_toc_field(doc)\n",
    "doc.add_page_break()\n",
    "\n",
    "# ----- Methods & Data -----\n",
    "doc.add_heading(\"Methods & Data\", level=1)\n",
    "doc.add_paragraph(\"We evaluate classical and quantum classifiers on PCA-reduced k-mer and one-hot encodings. \"\n",
    "                  \"Quantum models use an angle-embedding circuit with ring entanglement. \"\n",
    "                  \"Evaluation uses accuracy, precision, recall, F1, ROC-AUC, PR-AUC, specificity, balanced accuracy, and MCC.\")\n",
    "if enc_meta:\n",
    "    doc.add_paragraph(f\"Dataset: accession={enc_meta.get('accession','?')}, window={enc_meta.get('window','?')}, stride={enc_meta.get('stride','?')}, N={enc_meta.get('n_samples','?')}.\")\n",
    "\n",
    "# ----- Models -----\n",
    "doc.add_heading(\"Models\", level=2)\n",
    "doc.add_paragraph(\"- SVM_kmer (RBF) on standardized k-mer features.\\n\"\n",
    "                  \"- SVM_onehot (RBF) on flattened one-hot features.\\n\"\n",
    "                  \"- QSVM_kernel (precomputed quantum kernel with SVC(kernel='precomputed')).\\n\"\n",
    "                  \"- VQC (variational circuit classifier with Pauli-Z expectation).\")\n",
    "\n",
    "# ----- Executive Summary -----\n",
    "doc.add_heading(\"Executive Summary\", level=1)\n",
    "if not test_all.empty:\n",
    "    best = test_all.iloc[0]\n",
    "    base_txt = \"\"\n",
    "    if \"SVM_kmer\" in test_all[\"model\"].values:\n",
    "        base = test_all.set_index(\"model\").loc[\"SVM_kmer\"]\n",
    "        if not np.isnan(base[\"f1\"]):\n",
    "            base_txt = f\" (ΔF1 vs SVM_kmer: {best['f1']-base['f1']:+.3f})\"\n",
    "    doc.add_paragraph(f\"Best model: {best['model']} with F1={best['f1']:.3f}{base_txt}; \"\n",
    "                      f\"Acc={best['acc']:.3f}, Prec={best['prec']:.3f}, Rec={best['rec']:.3f}, \"\n",
    "                      f\"AUC={best['auc']:.3f}, PR-AUC={best.get('pr_auc',np.nan):.3f}.\")\n",
    "else:\n",
    "    doc.add_paragraph(\"Metrics not found; ensure training/evaluation notebooks were executed.\")\n",
    "\n",
    "# ----- Test Metrics Table (richer) -----\n",
    "doc.add_heading(\"Test Metrics (one per model)\", level=1)\n",
    "cols_main = [c for c in [\"model\",\"acc\",\"prec\",\"rec\",\"f1\",\"auc\",\"pr_auc\",\"specificity\",\"balanced_acc\",\"mcc\"] if c in test_all.columns]\n",
    "df_to_docx_table(doc, test_all[cols_main])\n",
    "\n",
    "# ----- Pairwise Statistical Comparison (McNemar) -----\n",
    "if mcnemar_stats:\n",
    "    doc.add_heading(\"Pairwise Comparison (McNemar’s test)\", level=1)\n",
    "    rows = []\n",
    "    for k, v in mcnemar_stats.items():\n",
    "        rows.append({\"comparison\":k, **v})\n",
    "    df_mc = pd.DataFrame(rows)[[\"comparison\",\"n01\",\"n10\",\"chi2\",\"p_approx\"]]\n",
    "    df_to_docx_table(doc, df_mc)\n",
    "else:\n",
    "    doc.add_paragraph(\"No McNemar statistics file found.\")\n",
    "\n",
    "# ----- Noise/Shot Top Configs -----\n",
    "if (not ns_vqc.empty) or (not ns_qsvm.empty):\n",
    "    doc.add_heading(\"Noise & Shots — Top Configurations\", level=1)\n",
    "    if 'best_vqc' in globals() and not best_vqc.empty:\n",
    "        doc.add_paragraph(\"VQC — top (mean test F1)\", style=\"Intense Quote\")\n",
    "        df_to_docx_table(doc, best_vqc)\n",
    "    if 'best_qsvm' in globals() and not best_qsvm.empty:\n",
    "        doc.add_paragraph(\"QSVM — top (mean test F1)\", style=\"Intense Quote\")\n",
    "        df_to_docx_table(doc, best_qsvm)\n",
    "\n",
    "# ----- Figures -----\n",
    "doc.add_heading(\"Figures\", level=1)\n",
    "for label, path in ART.items():\n",
    "    if not path: continue\n",
    "    doc.add_paragraph(label).alignment = 1\n",
    "    try:\n",
    "        doc.add_picture(path, width=Inches(6))\n",
    "    except Exception:\n",
    "        doc.add_paragraph(f\"(could not embed: {path})\")\n",
    "    cap = doc.add_paragraph(f\"Figure: {label}\")\n",
    "    cap.alignment = 1\n",
    "\n",
    "# ----- Limitations & Problems (from journals) -----\n",
    "doc.add_heading(\"Limitations & Problems\", level=1)\n",
    "if not journal.empty:\n",
    "    # show only WARN/FAIL, grouped by source\n",
    "    jsub = journal[journal[\"status\"].isin([\"warn\",\"fail\"])].copy()\n",
    "    if not jsub.empty:\n",
    "        add_section_landscape(doc)\n",
    "        grp = jsub.groupby(\"source\")\n",
    "        for src, chunk in grp:\n",
    "            doc.add_paragraph(f\"Source: {src}\", style=\"Intense Quote\")\n",
    "            df_to_docx_table(doc, chunk[[\"ts\",\"status\",\"step\",\"message\"]].reset_index(drop=True), style=\"Colorful List\")\n",
    "    else:\n",
    "        doc.add_paragraph(\"No warnings or failures recorded.\")\n",
    "else:\n",
    "    doc.add_paragraph(\"No journal logs found. If journaling was disabled, this section stays minimal.\")\n",
    "\n",
    "# ----- Timing Summary -----\n",
    "if timing:\n",
    "    doc.add_heading(\"Timing Summary\", level=1)\n",
    "    for block_name in [\"VQC\",\"QSVM\",\"VQC_actual\",\"QSVM_actual\"]:\n",
    "        dd = timing.get(block_name, {})\n",
    "        if not dd: continue\n",
    "        doc.add_paragraph(block_name, style=\"Intense Quote\")\n",
    "        for k, v in dd.items():\n",
    "            doc.add_paragraph(f\"- {k}: {v}\")\n",
    "\n",
    "# ----- Appendix: raw tables -----\n",
    "doc.add_heading(\"Appendix — Raw Tables\", level=1)\n",
    "try:\n",
    "    if not combined.empty:\n",
    "        doc.add_paragraph(\"Combined (test rows)\")\n",
    "        df_to_docx_table(doc, pick_test(combined)[cols_main], style=\"Light Shading Accent 1\")\n",
    "    if not m_qsvm.empty:\n",
    "        doc.add_paragraph(\"QSVM_kernel (all splits)\")\n",
    "        keep_cols = [c for c in [\"split\",\"acc\",\"prec\",\"rec\",\"f1\",\"auc\",\"pr_auc\",\"specificity\",\"balanced_acc\",\"mcc\",\"thr\"] if c in m_qsvm.columns]\n",
    "        df_to_docx_table(doc, m_qsvm[[\"split\"]+keep_cols[1:]].head(30))\n",
    "    if not ns_vqc.empty:\n",
    "        doc.add_paragraph(\"Noise Sweep — VQC (sample)\")\n",
    "        df_to_docx_table(doc, ns_vqc.head(30))\n",
    "    if not ns_qsvm.empty:\n",
    "        doc.add_paragraph(\"Noise Sweep — QSVM (sample)\")\n",
    "        df_to_docx_table(doc, ns_qsvm.head(30))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# ----- Save DOCX -----\n",
    "doc.save(str(DOCX_PATH))\n",
    "\n",
    "# ----- PDF (ReportLab preferred; fallback to Matplotlib multipage) -----\n",
    "if REPORTLAB_OK:\n",
    "    from reportlab.lib.pagesizes import A4\n",
    "    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image as RLImage, Table, TableStyle, PageBreak\n",
    "    from reportlab.lib.styles import getSampleStyleSheet\n",
    "    from reportlab.lib.units import inch\n",
    "    from reportlab.lib import colors\n",
    "\n",
    "    styles = getSampleStyleSheet()\n",
    "    h1, h2, body = styles[\"Title\"], styles[\"Heading2\"], styles[\"BodyText\"]\n",
    "    story = []\n",
    "\n",
    "    story.append(Paragraph(\"DNA QML — Results Report\", h1))\n",
    "    story.append(Paragraph(datetime.now().strftime(\"%Y-%m-%d %H:%M\"), body))\n",
    "    story.append(Spacer(1, 0.2*inch))\n",
    "\n",
    "    # Summary\n",
    "    story.append(Paragraph(\"Executive Summary\", h2))\n",
    "    if not test_all.empty:\n",
    "        best = test_all.iloc[0]\n",
    "        base_txt = \"\"\n",
    "        if \"SVM_kmer\" in test_all[\"model\"].values:\n",
    "            base = test_all.set_index(\"model\").loc[\"SVM_kmer\"]\n",
    "            if not np.isnan(base[\"f1\"]): base_txt = f\" (ΔF1 vs SVM_kmer: {best['f1']-base['f1']:+.3f})\"\n",
    "        story.append(Paragraph(f\"Best model: {best['model']} with F1={best['f1']:.3f}{base_txt}; \"\n",
    "                               f\"Acc={best['acc']:.3f}, Prec={best['prec']:.3f}, Rec={best['rec']:.3f}, \"\n",
    "                               f\"AUC={best['auc']:.3f}, PR-AUC={best.get('pr_auc',np.nan):.3f}.\", body))\n",
    "    if enc_meta:\n",
    "        story.append(Paragraph(f\"Accession: {enc_meta.get('accession','?')} — Window={enc_meta.get('window','?')}, \"\n",
    "                               f\"Stride={enc_meta.get('stride','?')}, N={enc_meta.get('n_samples','?')}.\", body))\n",
    "    story.append(Spacer(1, 0.15*inch))\n",
    "\n",
    "    # Test Metrics table\n",
    "    story.append(Paragraph(\"Test Metrics (one per model)\", h2))\n",
    "    data = [cols_main] + [[f\"{row[c]:.3f}\" if isinstance(row[c], float) else str(row[c]) for c in cols_main] for _, row in test_all.iterrows()]\n",
    "    tbl = Table(data, hAlign=\"LEFT\")\n",
    "    tbl.setStyle(TableStyle([\n",
    "        (\"BACKGROUND\", (0,0), (-1,0), colors.HexColor(\"#e8eef7\")),\n",
    "        (\"GRID\", (0,0), (-1,-1), 0.4, colors.grey),\n",
    "        (\"FONTNAME\", (0,0), (-1,0), \"Helvetica-Bold\"),\n",
    "        (\"ALIGN\", (1,1), (-1,-1), \"CENTER\"),\n",
    "    ]))\n",
    "    story.append(tbl)\n",
    "    story.append(Spacer(1, 0.2*inch))\n",
    "\n",
    "    # Timing (if any)\n",
    "    if timing:\n",
    "        story.append(Paragraph(\"Timing Summary\", h2))\n",
    "        for block_name in [\"VQC\",\"QSVM\",\"VQC_actual\",\"QSVM_actual\"]:\n",
    "            dd = timing.get(block_name, {})\n",
    "            if not dd: continue\n",
    "            story.append(Paragraph(f\"<b>{block_name}</b>\", body))\n",
    "            for k, v in dd.items():\n",
    "                story.append(Paragraph(f\"{k}: {v}\", body))\n",
    "        story.append(Spacer(1, 0.2*inch))\n",
    "\n",
    "    # Figures\n",
    "    story.append(Paragraph(\"Figures\", h2))\n",
    "    for label, path in ART.items():\n",
    "        if not path: continue\n",
    "        story.append(Paragraph(label, body))\n",
    "        try:\n",
    "            story.append(RLImage(path, width=6*inch))\n",
    "        except Exception:\n",
    "            story.append(Paragraph(f\"(could not embed: {path})\", body))\n",
    "        story.append(Spacer(1, 0.15*inch))\n",
    "\n",
    "    SimpleDocTemplate(str(PDF_PATH), pagesize=A4).build(story)\n",
    "else:\n",
    "    # Fallback: simple multipage PDF\n",
    "    from matplotlib.backends.backend_pdf import PdfPages\n",
    "    with PdfPages(str(PDF_PATH)) as pdf:\n",
    "        # Page 1: summary text\n",
    "        fig, ax = plt.subplots(figsize=(8.27, 11.69))\n",
    "        ax.axis(\"off\")\n",
    "        lines = [\"DNA QML — Results Report\", \"\", f\"Generated: {datetime.now():%Y-%m-%d %H:%M}\"]\n",
    "        for k, v in _sys_info().items():\n",
    "            lines.append(f\"{k}: {v}\")\n",
    "        lines.append(\"\")\n",
    "        if not test_all.empty:\n",
    "            lines.append(\"Test Metrics (top rows):\")\n",
    "            lines.append(test_all[cols_main].to_string(index=False))\n",
    "        ax.text(0.02, 0.98, \"\\n\".join(lines), va=\"top\", ha=\"left\", fontsize=10, family=\"monospace\")\n",
    "        pdf.savefig(fig); plt.close(fig)\n",
    "\n",
    "        # Add figures pages\n",
    "        for label, path in ART.items():\n",
    "            if not path: continue\n",
    "            img = plt.imread(path)\n",
    "            fig, ax = plt.subplots(figsize=(8.27, 11.69))\n",
    "            ax.imshow(img); ax.axis(\"off\")\n",
    "            ax.set_title(label)\n",
    "            pdf.savefig(fig); plt.close(fig)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" -\", DOCX_PATH)\n",
    "print(\" -\", PDF_PATH)\n",
    "\n",
    "# ---- Preview in notebook ----\n",
    "from IPython.display import display, Image as IPyImage\n",
    "print(\"\\nPreview — Test Metrics (DataFrame):\")\n",
    "display(test_all)\n",
    "\n",
    "for name in [\"bar_f1_test.png\",\"roc_test.png\",\"pr_test.png\"]:\n",
    "    p = FIGS/name\n",
    "    if p.exists():\n",
    "        display(IPyImage(filename=str(p)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
